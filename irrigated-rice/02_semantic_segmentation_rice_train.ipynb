{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_ltYdRQqvp9"
      },
      "source": [
        "Link para geração dos mosaicos:\n",
        "https://colab.research.google.com/drive/1C-ut9LLjuYH0hVXgvJK0kdD_i69AIpkJ?usp=sharing no colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1GKkAiU3vbQ"
      },
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "After adding the shortcut to the data in your Google Drive, the next step is to mount a Google Drive volume on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt_Mg55M3tfS",
        "outputId": "52470249-4e14-4076-c81f-f83edc0d63e6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFa0jBMnWEIR"
      },
      "source": [
        "# Check GPU\n",
        "\n",
        "We recommend that the entire model and classification training process be done using some of the GPUs available from Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmsT7NZ0YWHC",
        "outputId": "cf7ec42b-620d-4b21-eec7-b79fe1f001f0"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T7SsB0sFHZo"
      },
      "source": [
        "# Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdcHJiRBEiv4"
      },
      "outputs": [],
      "source": [
        "#Step 1\n",
        "!apt-get update\n",
        "#Step 2\n",
        "!apt-get install libgdal-dev -y\n",
        "#Step 3\n",
        "!apt-get install python-gdal -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ2koetlt85z"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ptqj8M7pt_AZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join, sep, exists\n",
        "import gc\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "from osgeo import gdal, osr\n",
        "from skimage.transform import resize, rotate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, \\\n",
        "    Conv2DTranspose, concatenate, BatchNormalization, Activation\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.utils import compute_class_weight\n",
        "from skimage import exposure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV6wHkfjIoas"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClOeVNyeUHOV"
      },
      "source": [
        "> Important:\n",
        "Create a folder to train follow the structure:\n",
        "1. TRAIN_LANDSAT_ARROZ\\\n",
        "    1.1 rice_train\\\n",
        "    1.2 rice_logs\\\n",
        "    1.3 predict\\\n",
        "    1.4 rice_predicted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjSCkwa0SHI4"
      },
      "outputs": [],
      "source": [
        "CHIP_SIZE = 256\n",
        "CHANNELS = 4\n",
        "LABELS = [0, 1]\n",
        "SPATIAL_SCALE = 30\n",
        "PROJECTION = 3857 # pseudo-mercator\n",
        "REPROJECT = False\n",
        "\n",
        "# Build Datasets\n",
        "GRIDS = 1\n",
        "ROTATE = True\n",
        "FLIP = False\n",
        "TRAIN_VALIDATION_DIR = [\"/content/drive/MyDrive/TRAIN_LANDSAT_ARROZ/rice_train\"]\n",
        "TRAIN_PATH = \"/content/train.h5\"\n",
        "VALIDATION_PATH = \"/content/validation.h5\"\n",
        "TEST_PATH = \"/content/test.h5\"\n",
        "COMPRESSION= 'gzip' # 'gzip' or None\n",
        "\n",
        "# Train model\n",
        "#TRAIN_BATCH_SIZE = 16 # para  16\n",
        "TRAIN_BATCH_SIZE = 5 # para 64\n",
        "TRAIN_EPOCHS = 100\n",
        "MODEL_DIR = \"/content/drive/MyDrive/TRAIN_LANDSAT_ARROZ/rice_logs\"\n",
        "\n",
        "# Predict images\n",
        "PREDICT_INPUT_DIR = \"/content/drive/MyDrive/TRAIN_LANDSAT_ARROZ/predict\"\n",
        "PREDICT_OUPUT_DIR = \"/content/drive/MyDrive/TRAIN_LANDSAT_ARROZ/predicted\"\n",
        "PREDICT_CHIP_SIZE = 256\n",
        "PREDICT_GRIDS = 1\n",
        "PREDICT_BATCH_SIZE = 1\n",
        "\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(PREDICT_OUPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df9erxjKFAPm"
      },
      "source": [
        "# Image Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pS9aROwLE1LN"
      },
      "outputs": [],
      "source": [
        "def load_file(path):\n",
        "    original_source = gdal.Open(path)\n",
        "\n",
        "    if REPROJECT:\n",
        "        new_source = reproject_dataset(original_source,\n",
        "                                    pixel_spacing=SPATIAL_SCALE,\n",
        "                                    epsg_to=PROJECTION)\n",
        "    else:\n",
        "        new_source = original_source\n",
        "\n",
        "    if not new_source is None:\n",
        "        bands = []\n",
        "        for index in range(1, new_source.RasterCount + 1):\n",
        "            band = new_source.GetRasterBand(index).ReadAsArray()\n",
        "            bands.append(band)\n",
        "\n",
        "        image = np.dstack(bands)\n",
        "\n",
        "        return original_source, new_source, image\n",
        "    else:\n",
        "        return original_source, new_source, None\n",
        "\n",
        "def normalize(image):\n",
        "    # image_mean = np.nanmean(image)\n",
        "    # image_std = np.nanstd(image)\n",
        "    # normalized = np.array( (image - image_mean) / image_std )\n",
        "    normalized = image / 255\n",
        "    return normalized\n",
        "\n",
        "\n",
        "def get_rotate(image):\n",
        "    images = []\n",
        "    for rot in [90, 180, 270]:\n",
        "        image_rotate = rotate(image, rot, preserve_range=True)\n",
        "        images.append(image_rotate)\n",
        "    return images\n",
        "\n",
        "def get_flip(image):\n",
        "    horizontal_flip = image[:, ::-1]\n",
        "    vertical_flip = image[::-1, :]\n",
        "    return [horizontal_flip, vertical_flip]\n",
        "\n",
        "def make_dataset(filename, width, height, channels):\n",
        "    dataset = h5py.File(filename, 'w')\n",
        "\n",
        "    x_data = dataset.create_dataset(\"x\", \n",
        "                                    (0, width, height, channels), \n",
        "                                    maxshape=(None, width, height, channels),\n",
        "                                    chunks=True, \n",
        "                                    compression=COMPRESSION)\n",
        "    \n",
        "    y_data = dataset.create_dataset(\"y\", \n",
        "                                    (0, width, height, 1), \n",
        "                                    maxshape=(None, width, height, 1),\n",
        "                                    chunks=True, \n",
        "                                    compression=COMPRESSION)\n",
        "    \n",
        "    return dataset, x_data, y_data\n",
        "\n",
        "def save_dataset(X, y, output_path, chip_size, channels):\n",
        "    if os.path.isfile(output_path):\n",
        "        dataset, x_data, y_data = load_dataset(output_path)\n",
        "    else:\n",
        "        dataset, x_data, y_data = make_dataset(output_path, \n",
        "                                               chip_size,\n",
        "                                               chip_size, \n",
        "                                               channels)\n",
        "\n",
        "    length = len(X)\n",
        "\n",
        "    x_data_size = x_data.len()\n",
        "    y_data_size = y_data.len()\n",
        "\n",
        "    x_data.resize((x_data_size + length, chip_size, chip_size, channels))\n",
        "    y_data.resize((y_data_size + length, chip_size, chip_size, 1))\n",
        "\n",
        "    print(\"Saving dataset...\" , len(X))\n",
        "    \n",
        "    x_data[y_data_size:] = X\n",
        "    y_data[y_data_size:] = y\n",
        "\n",
        "    dataset.close()\n",
        "\n",
        "def load_dataset(dataset, read_only=False):\n",
        "    if read_only:\n",
        "        dataset = h5py.File(dataset, 'r')\n",
        "    else:\n",
        "        dataset = h5py.File(dataset, 'r+')\n",
        "    \n",
        "    x_data = dataset[\"x\"]\n",
        "    y_data = dataset[\"y\"]\n",
        "\n",
        "    return dataset, x_data, y_data\n",
        "\n",
        "\n",
        "def mosaic_is_empty(image):\n",
        "    empty_percentage = (np.sum(np.sum(image == 0, axis=2) == CHANNELS) / (image.shape[0] * image.shape[1])) * 100\n",
        "    return empty_percentage >= 5\n",
        "\n",
        "\n",
        "def chip_is_empty(chip):\n",
        "    unique_labels = np.unique(chip)\n",
        "    return 0 in unique_labels and len(unique_labels) == 1\n",
        "\n",
        "\n",
        "def generate_dataset(image_path, labels_path, chip_size, channels, \n",
        "                     grids=1, allow_empty_chip=False, rotate=False, flip=False):\n",
        "    _, _, image_data = load_file(image_path)\n",
        "    _, _, image_labels = load_file(labels_path)\n",
        "\n",
        "    image_labels = resize(image_labels,\n",
        "                          (image_data.shape[0], image_data.shape[1]),\n",
        "                          preserve_range=True, anti_aliasing=True).astype(np.int8)\n",
        "\n",
        "    image = np.dstack([image_data, image_labels])\n",
        "\n",
        "    X_set = []\n",
        "    y_set = []\n",
        "\n",
        "    for step in get_grids(grids, chip_size):\n",
        "        for (x, y, window, dimension) in sliding_window(image,\n",
        "                                                        step[\"steps\"],\n",
        "                                                        step[\"chip_size\"],\n",
        "                                                        (chip_size,\n",
        "                                                         chip_size)):\n",
        "\n",
        "            train = np.array(window[:, :, : channels])\n",
        "\n",
        "            labels = np.array(window[:, :, -1:], dtype=np.int8)\n",
        "\n",
        "            unique_labels = np.unique(labels)\n",
        "            \n",
        "            if (chip_is_empty(labels) or mosaic_is_empty(train)) and not allow_empty_chip:\n",
        "                continue\n",
        "\n",
        "            # if mosaic_is_empty(train) and not allow_empty_chip or set(unique_labels) != set(LABELS):\n",
        "            #     continue\n",
        "\n",
        "            raw_image = np.dstack([train, labels])\n",
        "            images_daugmentation = [raw_image]\n",
        "            \n",
        "            if rotate:\n",
        "                images_rotate = get_rotate(raw_image)\n",
        "                images_daugmentation.extend(images_rotate)\n",
        "\n",
        "            if flip:\n",
        "                images_flip = []\n",
        "                for im in images_daugmentation:\n",
        "                    images_flip.extend(get_flip(im))\n",
        "                images_daugmentation.extend(images_flip)\n",
        "\n",
        "            X_group = []\n",
        "            Y_group = []\n",
        "\n",
        "            for i in images_daugmentation:\n",
        "                new_train = np.array(i[:, :, :channels])\n",
        "                new_labels = np.array(i[:, :, -1:], dtype=np.int8)\n",
        "\n",
        "                np.clip(new_labels, 0, None, out=new_labels)\n",
        "                \n",
        "                X_group.append(new_train)\n",
        "                Y_group.append(new_labels)\n",
        "\n",
        "            X_set.append(X_group)\n",
        "            y_set.append(Y_group)\n",
        "\n",
        "        X_set = np.array(X_set)\n",
        "        y_set = np.array(y_set)\n",
        "\n",
        "        yield X_set, y_set\n",
        "\n",
        "\n",
        "def generate_train_validation_dataset(image_path, labels_path, \n",
        "                                      train_path, validation_path, test_path, \n",
        "                                      chip_size, \n",
        "                                      channels=1, \n",
        "                                      grids=1, \n",
        "                                      allow_empty_chip=False, \n",
        "                                      rotate=False, flip=False):\n",
        "    \n",
        "    for X_set, y_set in generate_dataset(image_path, labels_path, \n",
        "                                    chip_size=chip_size,\n",
        "                                    channels=channels, \n",
        "                                    grids=grids, \n",
        "                                    allow_empty_chip=allow_empty_chip, \n",
        "                                    rotate=rotate, \n",
        "                                    flip=flip):\n",
        "        \n",
        "        if len(X_set) >= 5:\n",
        "            X_train, X_val, y_train, y_val = train_test_split(X_set, y_set,\n",
        "                                                        test_size=0.30,\n",
        "                                                        random_state=1)\n",
        "            \n",
        "            X_val, X_test, y_val, y_test = train_test_split(X_val, y_val,\n",
        "                                                        test_size=0.30,\n",
        "                                                        random_state=1)\n",
        "\n",
        "            X_train =  np.array([item for sublist in X_train for item in sublist])\n",
        "            y_train =  np.array([item for sublist in y_train for item in sublist])\n",
        "\n",
        "            X_val =  np.array([item for sublist in X_val for item in sublist])\n",
        "            y_val =  np.array([item for sublist in y_val for item in sublist])\n",
        "\n",
        "            X_test =  np.array([item for sublist in X_test for item in sublist])\n",
        "            y_test =  np.array([item for sublist in y_test for item in sublist])\n",
        "\n",
        "            save_dataset(X_train, y_train, train_path, chip_size, channels)\n",
        "            save_dataset(X_val, y_val, validation_path, chip_size, channels)\n",
        "            save_dataset(X_test, y_test, test_path, chip_size, channels)\n",
        "\n",
        "def sliding_window(image, step, chip_size, chip_resize):\n",
        "    # slide a chip across the image\n",
        "    step_cols = int(step[0])\n",
        "    step_rows = int(step[1])\n",
        "\n",
        "    cols = image.shape[1]\n",
        "    rows = image.shape[0]\n",
        "\n",
        "    chip_size_cols = chip_size[0]\n",
        "    chip_size_rows = chip_size[1]\n",
        "\n",
        "    chip_resize_cols = chip_resize[0]\n",
        "    chip_resize_rows = chip_resize[1]\n",
        "\n",
        "    for y in range(0, rows, step_rows):\n",
        "        for x in range(0, cols, step_cols):\n",
        "\n",
        "            origin_x = x\n",
        "            origin_y = y\n",
        "\n",
        "            if (origin_y + chip_size_rows) > rows:\n",
        "                origin_y = rows - chip_size_rows\n",
        "\n",
        "            if (origin_x + chip_size_cols) > cols:\n",
        "                origin_x = cols - chip_size_cols\n",
        "\n",
        "            chip = image[origin_y:origin_y + chip_size_rows,\n",
        "                   origin_x: origin_x + chip_size_cols]\n",
        "\n",
        "            original_shape = chip.shape\n",
        "\n",
        "            if chip.shape != (chip_resize_cols, chip_resize_rows):\n",
        "                chip = resize(chip,\n",
        "                              (chip_resize_cols, chip_resize_rows),\n",
        "                              preserve_range=True,\n",
        "                              anti_aliasing=True)\n",
        "\n",
        "            yield (origin_x, origin_y, chip, original_shape)\n",
        "\n",
        "\n",
        "def get_window(matrix, x, y, width, height):\n",
        "    return matrix[y:y + height, x:x + width]\n",
        "\n",
        "\n",
        "def set_window(matrix, x, y, new_matrix):\n",
        "    for i_index, i in enumerate(range(y, y + new_matrix.shape[0])):\n",
        "        for j_index, j in enumerate(range(x, x + new_matrix.shape[1])):\n",
        "            matrix[i][j] = new_matrix[i_index][j_index]\n",
        "\n",
        "\n",
        "def transform_labels(labels_array, labels):\n",
        "    lb = preprocessing.LabelBinarizer()\n",
        "    lb.fit(labels)\n",
        "    new_labels_array = []\n",
        "    for ix, l in enumerate(labels_array):\n",
        "        flat_labels = l.reshape((l.shape[0] * l.shape[1],))\n",
        "        transformed_flat_labels = lb.transform(flat_labels)\n",
        "        new_labels_array.append(transformed_flat_labels.reshape(\n",
        "            (l.shape[0], l.shape[1], len(labels))))\n",
        "\n",
        "    new_labels_array = np.array(new_labels_array)\n",
        "    return new_labels_array\n",
        "\n",
        "\n",
        "def get_grids(grids, chip_size):\n",
        "    grids_dict = {\n",
        "        1: [\n",
        "            {\"steps\": (chip_size, chip_size),\n",
        "             \"chip_size\": (chip_size, chip_size)}\n",
        "        ],\n",
        "        2: [\n",
        "            {\"steps\": (int(chip_size * 0.5), int(chip_size * 0.5)),\n",
        "             \"chip_size\": (chip_size, chip_size)},\n",
        "        ],\n",
        "        3: [\n",
        "            {\"steps\": (int(chip_size * 0.9), int(chip_size * 0.9)),\n",
        "             \"chip_size\": (chip_size, chip_size)},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return grids_dict[grids]\n",
        "\n",
        "\n",
        "def reproject_dataset(g, pixel_spacing=30., epsg_to=3857):\n",
        "    osng = osr.SpatialReference()\n",
        "    osng.ImportFromEPSG(epsg_to)\n",
        "\n",
        "    wkt = g.GetProjection()\n",
        "    wgs84 = osr.SpatialReference()\n",
        "    wgs84.ImportFromWkt(wkt)\n",
        "\n",
        "    tx = osr.CoordinateTransformation(wgs84, osng)\n",
        "    # Up to here, all  the projection have been defined, as well as a\n",
        "    # transformation from the from to the  to :)\n",
        "\n",
        "    # Get the Geotransform vector\n",
        "    geo_t = g.GetGeoTransform()\n",
        "    x_size = g.RasterXSize  # Raster xsize\n",
        "    y_size = g.RasterYSize  # Raster ysize\n",
        "    # Work out the boundaries of the new dataset in the target projection\n",
        "    (ulx, uly, ulz) = tx.TransformPoint(geo_t[0], geo_t[3])\n",
        "    (lrx, lry, lrz) = tx.TransformPoint(geo_t[0] + geo_t[1] * x_size, \\\n",
        "                                        geo_t[3] + geo_t[5] * y_size)\n",
        "\n",
        "    # Now, we create an in-memory raster\n",
        "    mem_drv = gdal.GetDriverByName('MEM')\n",
        "    # The size of the raster is given the new projection and pixel spacing\n",
        "    # Using the values we calculated above. Also, setting it to store one band\n",
        "    # and to use Float32 data type.\n",
        "    dest = mem_drv.Create('', int((lrx - ulx) / pixel_spacing), \\\n",
        "                          int((uly - lry) / pixel_spacing), g.RasterCount,\n",
        "                          g.GetRasterBand(1).DataType)\n",
        "    # Calculate the new geotransform\n",
        "    new_geo = (ulx, pixel_spacing, geo_t[2], \\\n",
        "               uly, geo_t[4], -pixel_spacing)\n",
        "    # Set the geotransform\n",
        "    dest.SetGeoTransform(new_geo)\n",
        "    dest.SetProjection(osng.ExportToWkt())\n",
        "    # Perform the projection/resampling\n",
        "    res = gdal.ReprojectImage(g, dest, \\\n",
        "                              wgs84.ExportToWkt(), osng.ExportToWkt(), \\\n",
        "                              gdal.GRA_NearestNeighbour)\n",
        "    return dest\n",
        "\n",
        "\n",
        "\n",
        "def save_results(original_dataset, reprojected_dataset, image, output_path):\n",
        "    mem_dataset = reprojected_dataset \\\n",
        "        .GetDriver() \\\n",
        "        .Create(output_path, image.shape[1], image.shape[0], 1, gdal.GDT_Int16)\n",
        "\n",
        "    mem_dataset.SetGeoTransform(reprojected_dataset.GetGeoTransform())\n",
        "    mem_dataset.SetProjection(reprojected_dataset.GetProjection())\n",
        "    mem_dataset.GetRasterBand(1) \\\n",
        "        .WriteArray(image.reshape((image.shape[0], image.shape[1])), 0, 0)\n",
        "    mem_dataset.FlushCache()\n",
        "\n",
        "    original_epsg = int(osr \\\n",
        "                        .SpatialReference(wkt=original_dataset.GetProjection()) \\\n",
        "                        .GetAttrValue('AUTHORITY', 1))\n",
        "\n",
        "    output_dataset = reproject_dataset(mem_dataset,\n",
        "                                       SPATIAL_SCALE,\n",
        "                                       original_epsg)\n",
        "\n",
        "    original_dataset.GetDriver().CreateCopy(output_path,\n",
        "                                            output_dataset,\n",
        "                                            options=['COMPRESS=LZW',\n",
        "                                                     'TFW=YES'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y0o-ByLglK3"
      },
      "source": [
        "# Build Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DydlXKwXKt1n"
      },
      "source": [
        "## Build Train, Validation and Test datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzuSbSOAJtlq",
        "outputId": "ca1bb8c5-fcf7-4217-df18-56e58a6a7e39"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "for path in TRAIN_VALIDATION_DIR:\n",
        "\n",
        "    images = [f for f in glob.glob(path + \"/*mosaic.tif\", recursive=True)]\n",
        "\n",
        "    if len(images) == 0:\n",
        "        print(\"No samples found.\")\n",
        "\n",
        "    for image_path in images:\n",
        "        labels_path = image_path.replace(\"mosaic\", \"labels\")\n",
        "        print(image_path)\n",
        "        print(labels_path)\n",
        "        generate_train_validation_dataset(\n",
        "            image_path=image_path,\n",
        "            labels_path=labels_path,\n",
        "            train_path=TRAIN_PATH,\n",
        "            validation_path=VALIDATION_PATH,\n",
        "            test_path=TEST_PATH,\n",
        "            chip_size=CHIP_SIZE,\n",
        "            channels=CHANNELS,\n",
        "            grids=GRIDS,\n",
        "            rotate=ROTATE\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIhJy8c7Kwgn"
      },
      "source": [
        "## Plot Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "cAGlCBcZK5Ay",
        "outputId": "66034412-c269-46e9-b44f-6bb4de470995"
      },
      "outputs": [],
      "source": [
        "def plot_figures(figures, nrows = 1, ncols=1):\n",
        "    \"\"\"Plot a dictionary of figures.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    figures : <title, figure> dictionary\n",
        "    ncols : number of columns of subplots wanted in the display\n",
        "    nrows : number of rows of subplots wanted in the figure\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=(19, 10))\n",
        "    for ind,title in zip(range(len(figures)), figures):\n",
        "        image = figures[title]\n",
        "        if image.shape[2] >= 3:\n",
        "            image = image[:, : , :3]\n",
        "            for i in range(3):\n",
        "                band = image[:,:,i]\n",
        "                in_low, in_high = np.percentile(band, (2, 98))\n",
        "                band = exposure.rescale_intensity(band, in_range=(in_low, in_high))\n",
        "                image[:,:,i] = band\n",
        "            axeslist.ravel()[ind].imshow(image)\n",
        "        else:\n",
        "            image = image.reshape((image.shape[0], image.shape[1]))\n",
        "            print(\"Labels: \", np.unique(image))\n",
        "            axeslist.ravel()[ind].imshow(image, vmin=LABELS[0], vmax=LABELS[-1])\n",
        "\n",
        "        axeslist.ravel()[ind].set_title(title)\n",
        "        axeslist.ravel()[ind].set_axis_off()\n",
        "    plt.tight_layout() # optional\n",
        "\n",
        "figures = {}\n",
        "\n",
        "dataset, x, y = load_dataset(TRAIN_PATH, read_only=True)\n",
        "\n",
        "ids = []\n",
        "\n",
        "samples = 4\n",
        "\n",
        "for i in range(0, samples):\n",
        "    id = random.randint(0,x.shape[0]-1)\n",
        "    print(id)\n",
        "    figures['img_x'+ str(i)] = x[id]\n",
        "    figures['img_y'+ str(i)] = y[id]\n",
        "\n",
        "plot_figures(figures, 2, samples)\n",
        "dataset.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lg5wCFdQBbMq"
      },
      "source": [
        "## Calculate classes proportion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Fmb-UPURlW",
        "outputId": "2cfc8910-1054-47d9-cb7e-3f9778873f43"
      },
      "outputs": [],
      "source": [
        "dataset, x, y = load_dataset(VALIDATION_PATH, read_only=True)\n",
        "\n",
        "print(\"Shapes:\", x.shape, y.shape)\n",
        "\n",
        "y_values = np.array(y).reshape(y.shape[0] * y.shape[1] * y.shape[2])\n",
        "\n",
        "unique, counts = np.unique(y_values, return_counts=True)\n",
        "labels_count = dict(zip(unique, counts))\n",
        "\n",
        "total = sum(labels_count.values())\n",
        "\n",
        "for label_value in LABELS:\n",
        "    print(\"Label: {} Proportion: {}\".format(label_value, labels_count.get(label_value) / total))\n",
        "\n",
        "dataset.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlJYgRBtCLb6"
      },
      "source": [
        "## Calculte classe weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9IpbfX19686",
        "outputId": "4d54d571-6f10-4bf8-d061-3c71d3c698fd"
      },
      "outputs": [],
      "source": [
        "weights = compute_class_weight('balanced', LABELS, y_values)\n",
        "class_weights = dict(zip(LABELS, weights))\n",
        "class_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOCNbbIp03Df"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gM7XiDX6nfps"
      },
      "source": [
        "## Define losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVFCf3ARniqO"
      },
      "outputs": [],
      "source": [
        "def categorical_focal_loss(gamma=2., alpha=.25):\n",
        "    \"\"\"\n",
        "    Softmax version of focal loss.\n",
        "\n",
        "           m\n",
        "      FL = ∑  -alpha * (1 - p_o,c)^gamma * y_o,c * log(p_o,c)\n",
        "          c=1\n",
        "\n",
        "      where m = number of classes, c = class and o = observation\n",
        "\n",
        "    Parameters:\n",
        "      alpha -- the same as weighing factor in balanced cross entropy\n",
        "      gamma -- focusing parameter for modulating factor (1-p)\n",
        "\n",
        "    Default value:\n",
        "      gamma -- 2.0 as mentioned in the paper\n",
        "      alpha -- 0.25 as mentioned in the paper\n",
        "\n",
        "    References:\n",
        "        Official paper: https://arxiv.org/pdf/1708.02002.pdf\n",
        "        https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n",
        "\n",
        "    Usage:\n",
        "     model.compile(loss=[categorical_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
        "    \"\"\"\n",
        "    def categorical_focal_loss_fixed(y_true, y_pred):\n",
        "        \"\"\"\n",
        "        :param y_true: A tensor of the same shape as `y_pred`\n",
        "        :param y_pred: A tensor resulting from a softmax\n",
        "        :return: Output tensor.\n",
        "        \"\"\"\n",
        "\n",
        "        y_true = K.cast(y_true, \"float32\")\n",
        "        y_pred = K.cast(y_pred, \"float32\")\n",
        "\n",
        "        # Scale predictions so that the class probas of each sample sum to 1\n",
        "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "\n",
        "        # Clip the prediction value to prevent NaN's and Inf's\n",
        "        epsilon = K.epsilon()\n",
        "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
        "\n",
        "        # Calculate Cross Entropy\n",
        "        cross_entropy = -y_true * K.log(y_pred)\n",
        "\n",
        "        # Calculate Focal Loss\n",
        "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
        "\n",
        "        # Sum the losses in mini_batch\n",
        "        return K.sum(loss, axis=1)\n",
        "\n",
        "    return categorical_focal_loss_fixed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyYJFIBt8trV"
      },
      "source": [
        "## Define metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efGTRlKZ8uT0"
      },
      "outputs": [],
      "source": [
        "def jaccard_coef(y_true, y_pred):\n",
        "    smooth = 1e-12\n",
        "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
        "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    return K.mean(jac)\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b458qR8pRMU"
      },
      "source": [
        "## U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9uL77bj08t6"
      },
      "outputs": [],
      "source": [
        "def conv2d_block(n_filters, kernel_size, activation='relu', inputs=None):\n",
        "    net = Conv2D(filters=n_filters, \n",
        "                 kernel_size=kernel_size, \n",
        "                 activation=None,\n",
        "                 kernel_initializer='he_normal',\n",
        "                 padding='same') (inputs) \n",
        "    net = BatchNormalization()(net)\n",
        "    net = Activation(activation)(net)\n",
        "\n",
        "    net = Conv2D(filters=n_filters, \n",
        "                 kernel_size=kernel_size, \n",
        "                 activation=None,\n",
        "                 kernel_initializer='he_normal', \n",
        "                 padding='same') (net) \n",
        "    net = BatchNormalization()(net)\n",
        "    net = Activation(activation)(net)\n",
        "\n",
        "    return net\n",
        "\n",
        "def transpose(n_filters, kernel_size, inputs=None):\n",
        "    net = Conv2DTranspose(n_filters, \n",
        "                          kernel_size, \n",
        "                          strides=(2, 2),\n",
        "                          padding='same') (inputs)\n",
        "    return net\n",
        "\n",
        "def model_fn(input_shape, n_filters=16, dropout = 0.5, labels=[]): # parâmetro n_filters\n",
        "    inputs = keras.Input(input_shape)\n",
        "\n",
        "    c1 = conv2d_block(n_filters * 1, (3, 3), inputs=inputs)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "    c2 = conv2d_block(n_filters * 2, (3, 3), inputs=p1)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "    c3 = conv2d_block(n_filters * 4, (3, 3), inputs=p2)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "    c4 = conv2d_block(n_filters * 8, (3, 3), inputs=p3)\n",
        "    c4 = Dropout(dropout) (c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "    c5 = conv2d_block(n_filters * 16, (3, 3), inputs=p4)\n",
        "    c5 = Dropout(dropout) (c5)\n",
        "\n",
        "    u6 = transpose(n_filters * 8, (2, 2), inputs=c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = conv2d_block(n_filters * 8, (2, 2), inputs=u6)\n",
        "    \n",
        "    u7 = transpose(n_filters * 4, (2, 2), inputs=c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = conv2d_block(n_filters * 4, (2, 2), inputs=u7)\n",
        "\n",
        "    u8 = transpose(n_filters * 2, (2, 2), inputs=c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = conv2d_block(n_filters * 2, (2, 2), inputs=u8)\n",
        "    \n",
        "    u9 = transpose(n_filters * 1, (2, 2), inputs=c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = conv2d_block(n_filters * 1, (2, 2), inputs=u9)\n",
        "    \n",
        "    if len(labels) > 2:\n",
        "        outputs = tf.keras.layers.Conv2D(len(labels), 1, 1, \n",
        "                                         activation='sigmoid')(c9)\n",
        "        loss_function = categorical_focal_loss()\n",
        "        metrics = [jaccard_coef, dice_coef]\n",
        "    else:\n",
        "        outputs = tf.keras.layers.Conv2D(1, (1, 1), \n",
        "                                         activation='sigmoid')(c9)\n",
        "        loss_function = 'binary_crossentropy'\n",
        "        metrics = [jaccard_coef, dice_coef]\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer='adam', loss=loss_function, \n",
        "                  metrics=[jaccard_coef, dice_coef])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyfS7rI82Dj4"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngmo5JVC2DzF"
      },
      "outputs": [],
      "source": [
        "class Classifier(object):\n",
        "    def __init__(self, chip_size, channels, model_dir, labels, to_save_model=False):\n",
        "        self.__chip_size = chip_size\n",
        "        self.__channels = channels\n",
        "        self.__labels = labels\n",
        "\n",
        "        if to_save_model:\n",
        "            self.__model = model_fn((None, None, channels), labels=labels)\n",
        "        else:\n",
        "            self.__model = model_fn((chip_size, chip_size, channels), labels=labels)\n",
        "\n",
        "        if not os.path.exists(model_dir):\n",
        "            os.makedirs(model_dir)\n",
        "\n",
        "        self.load_model(model_dir)\n",
        "        self.load_callbacks(model_dir)\n",
        "\n",
        "    def load_model(self, model_dir):\n",
        "        latest = tf.train.latest_checkpoint(model_dir)\n",
        "\n",
        "        if latest:\n",
        "            print('Loading model....')\n",
        "            self.__model.load_weights(latest)\n",
        "\n",
        "        print('Model loaded!')\n",
        "        self.__model.summary()\n",
        "        tf.keras.utils.plot_model(self.__model, show_shapes=True)\n",
        "\n",
        "    def get_model(self):\n",
        "        return self.__model\n",
        "\n",
        "    def load_callbacks(self, model_dir):\n",
        "        es_cp_callback = tf.keras.callbacks. \\\n",
        "            EarlyStopping(patience=20, \n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True)\n",
        "        \n",
        "        checkpoint_path = '{dir}/model.ckpt'.format(dir=model_dir)\n",
        "        cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_path,\n",
        "            save_weights_only=True,\n",
        "            save_best_only=True)\n",
        "\n",
        "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=model_dir)\n",
        "\n",
        "        self.__callbacks = [es_cp_callback, cp_callback, tensorboard_callback]\n",
        "\n",
        "\n",
        "    def train(self, input_train, input_validation, epochs, batch_size, generator=None, data_porportion=None):\n",
        "        train_dataset, train_data, train_labels = load_dataset(input_train,\n",
        "                                                            read_only=True)\n",
        "        validation_dataset, validation_data, validation_labels = load_dataset(\n",
        "            input_validation, read_only=True)\n",
        "        \n",
        "        print(train_data.shape)\n",
        "        print(validation_data.shape)\n",
        "\n",
        "        if data_porportion not in [None, 1]:\n",
        "            train_proportion = int(len(train_data) * data_porportion)\n",
        "            validation_proportion = int(len(validation_data) * data_porportion)\n",
        "\n",
        "            train_data = train_data[:train_proportion]\n",
        "            train_labels = train_labels[:train_proportion]\n",
        "            validation_data = validation_data[:train_proportion]\n",
        "            validation_labels = validation_labels[:train_proportion]\n",
        "            \n",
        "        if generator:\n",
        "            history = self.__model.fit(generator(train_data, train_labels, batch_size, self.__labels), \n",
        "                    steps_per_epoch=len(train_data)//batch_size, \n",
        "                    epochs=epochs,\n",
        "                    validation_data=generator(validation_data, validation_labels, batch_size, self.__labels),\n",
        "                    validation_steps=len(validation_data)//batch_size,\n",
        "                    callbacks=self.__callbacks)\n",
        "            \n",
        "        else:\n",
        "            train_images = np.asarray(train_data, dtype=np.float32)\n",
        "            train_labels = np.asarray(train_labels, dtype=np.int8)\n",
        "\n",
        "            validation_images = np.asarray(validation_data, dtype=np.float32)\n",
        "            validation_labels = np.asarray(validation_labels, dtype=np.int8)\n",
        "\n",
        "            if len(self.__labels) > 2:\n",
        "                train_labels = transform_labels(train_labels, self.__labels)\n",
        "                validation_labels = transform_labels(validation_labels,\n",
        "                                                    self.__labels)\n",
        "\n",
        "            history = self.__model.fit(x=train_images,\n",
        "                            y=train_labels,\n",
        "                            validation_data=(validation_images, validation_labels),\n",
        "                            epochs=epochs,\n",
        "                            batch_size=batch_size,\n",
        "                            verbose=1,\n",
        "                            callbacks=self.__callbacks)\n",
        "        \n",
        "        fig, ax = plt.subplots(3,1, figsize=(15, 10))\n",
        "        ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "        ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "        legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "        ax[1].plot(history.history['jaccard_coef'], color='b', label=\"Training Jaccard Index\")\n",
        "        ax[1].plot(history.history['val_jaccard_coef'], color='r',label=\"Validation Jaccard Index\")\n",
        "        legend = ax[1].legend(loc='best', shadow=True)\n",
        "\n",
        "        ax[2].plot(history.history['dice_coef'], color='b', label=\"Training Dice Index\")\n",
        "        ax[2].plot(history.history['val_dice_coef'], color='r',label=\"Validation Dice Index\")\n",
        "        legend = ax[2].legend(loc='best', shadow=True)\n",
        "\n",
        "        plt.plot()\n",
        "\n",
        "        train_dataset.close()\n",
        "        validation_dataset.close()\n",
        "\n",
        "    def evaluate(self, input_test):\n",
        "        test_dataset, test_data, test_labels = load_dataset(input_test,\n",
        "                                                            read_only=True)\n",
        "        \n",
        "        test_images = normalize(np.asarray(test_data, dtype=np.float32))\n",
        "        test_labels = np.asarray(test_labels, dtype=np.int8)\n",
        "\n",
        "        if len(self.__labels) > 2:\n",
        "            test_labels = transform_labels(test_labels, self.__labels)\n",
        "\n",
        "        self.__model.evaluate(x=test_images,\n",
        "                            y=test_labels,\n",
        "                            batch_size=1)\n",
        "        \n",
        "\n",
        "    def predict(self, input_path, output_path, grids, batch_size):\n",
        "        original_dataset, input_dataset, image = load_file(input_path)\n",
        "\n",
        "        print('dataset loaded')\n",
        "\n",
        "        image = image[:, :, : self.__channels]\n",
        "\n",
        "        image = normalize(image)\n",
        "\n",
        "        predicted_image = np.zeros((image.shape[0], image.shape[1]),\n",
        "                                   dtype=np.int8)\n",
        "\n",
        "        grids = get_grids(grids, self.__chip_size)\n",
        "\n",
        "        for step in grids:\n",
        "            batch = []\n",
        "            windows = sliding_window(image, step['steps'], step['chip_size'],\n",
        "                                     (self.__chip_size, self.__chip_size))\n",
        "\n",
        "            for (x, y, chip, original_dimensions) in tqdm(iterable=windows,\n",
        "                                                          miniters=10,\n",
        "                                                          unit=' windows'):\n",
        "\n",
        "                batch.append({'chip': chip, 'x': x, 'y': y, \n",
        "                              'dimensions': original_dimensions})\n",
        "\n",
        "                if len(batch) >= batch_size:\n",
        "                    chips = []\n",
        "                    positions = []\n",
        "                    dimensions = []\n",
        "\n",
        "                    for b in batch:\n",
        "                        chips.append(b.get('chip'))\n",
        "                        positions.append((b.get('x'), b.get('y')))\n",
        "                        dimensions.append(b.get('dimensions'))\n",
        "\n",
        "                    chips = np.array(chips, dtype=np.float32)\n",
        "\n",
        "                    pred = self.__model.predict(chips, batch_size=batch_size)\n",
        "\n",
        "                    for chip, position, dimension, predict in zip(chips,\n",
        "                                                                  positions,\n",
        "                                                                  dimensions,\n",
        "                                                                  pred):\n",
        "\n",
        "                        if len(self.__labels) > 2:\n",
        "                            predict = np.array(tf.math.argmax(predict, axis=2))\n",
        "                        else:\n",
        "                            predict[predict > 0.5] = 1\n",
        "                            predict[predict <= 0.5] = 0\n",
        "\n",
        "                        predict = resize(predict, (dimension[0], dimension[1]),\n",
        "                                         preserve_range=True,\n",
        "                                         anti_aliasing=True).astype(np.int8)\n",
        "\n",
        "                        predict = predict.reshape(\n",
        "                            (predict.shape[0], predict.shape[1]))\n",
        "\n",
        "                        predicted = get_window(predicted_image,\n",
        "                                               position[0],\n",
        "                                               position[1],\n",
        "                                               predict.shape[1],\n",
        "                                               predict.shape[0])\n",
        "\n",
        "                        if predict.shape != predicted.shape:\n",
        "                            raise Exception('predict.shape != predicted.shape')\n",
        "\n",
        "                        if len(self.__labels) > 2:\n",
        "                            set_window(predicted_image, position[0],\n",
        "                                       position[1], predict)\n",
        "                        else:\n",
        "                            set_window(predicted_image, position[0],\n",
        "                                       position[1], np.add(predict, predicted))\n",
        "\n",
        "                    batch = []\n",
        "\n",
        "            if len(self.__labels) == 2:\n",
        "                predicted_image[predicted_image >= 1] = 1\n",
        "                \n",
        "            print('Saving results...')\n",
        "            save_results(original_dataset, input_dataset, predicted_image,\n",
        "                      output_path)\n",
        "\n",
        "            del original_dataset, input_dataset, image, predicted_image\n",
        "            gc.collect()\n",
        "            print('Finished!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G62gUubn1eme"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdAgZ-n-hjS9"
      },
      "source": [
        "## Build Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5HVEyumhknt"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, x_data, y_data=None, batch_size=32, labels=None, shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.indices = range(len(x_data))\n",
        "        self.shuffle = shuffle\n",
        "        self.x_data = x_data\n",
        "        self.y_data = y_data\n",
        "        self.labels = labels\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X, y = self.__get_data(start=index, end=index + self.batch_size)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.index = np.arange(len(self.indices))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.index)\n",
        "\n",
        "    def __get_data(self, start, end):\n",
        "        X = normalize(np.asarray(self.x_data[start:end])).astype(np.float32)\n",
        "        y = np.asarray(self.y_data[start:end], dtype=np.int8)\n",
        "\n",
        "        if len(self.labels) > 2:\n",
        "                y = transform_labels(y, self.labels)\n",
        "        \n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQXkIsGIk8f5"
      },
      "source": [
        "## Run Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nIlTEjQymfFY",
        "outputId": "52abb846-1067-4410-a6b9-b35943000c46"
      },
      "outputs": [],
      "source": [
        "classifier = Classifier(chip_size=CHIP_SIZE, channels=CHANNELS, \n",
        "                        model_dir=MODEL_DIR, labels=LABELS)\n",
        "\n",
        "classifier.train(input_train=TRAIN_PATH, input_validation=VALIDATION_PATH, \n",
        "                epochs=TRAIN_EPOCHS, batch_size=TRAIN_BATCH_SIZE, \n",
        "                generator=DataGenerator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM_50EXd9qGt"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bnmOShQsVh_"
      },
      "source": [
        "## Run evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aMeQopn9s6Q",
        "outputId": "b4bfb082-fc80-482d-f9df-0443b81097e9"
      },
      "outputs": [],
      "source": [
        "classifier = Classifier(chip_size=CHIP_SIZE,\n",
        "                        channels=CHANNELS,\n",
        "                        model_dir=MODEL_DIR,\n",
        "                        labels=LABELS)\n",
        "\n",
        "classifier.evaluate(input_test=TEST_PATH)\n",
        "\n",
        "model = classifier.get_model()\n",
        "model.save(MODEL_DIR + \"/model.h5\")\n",
        "\n",
        "del classifier, model\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQRqOn292cJs"
      },
      "source": [
        "# Predict Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDcbK0cn2cfc",
        "outputId": "a86f2a9e-2bec-4368-f3d8-d9e6b629ce8b"
      },
      "outputs": [],
      "source": [
        "classifier = Classifier(chip_size=PREDICT_CHIP_SIZE,\n",
        "                        channels=CHANNELS,\n",
        "                        model_dir=MODEL_DIR,\n",
        "                        labels=LABELS)\n",
        "\n",
        "files = [f for f in listdir(PREDICT_INPUT_DIR) if\n",
        "         isfile(join(PREDICT_INPUT_DIR, f))]\n",
        "\n",
        "if len(files) == 0:\n",
        "    print(\"No file found.\")\n",
        "\n",
        "for f in files:\n",
        "    print(\"File:\", f)\n",
        "    input_file = \"{directory}/{filepath}\".format(directory=PREDICT_INPUT_DIR, filepath=f)\n",
        "\n",
        "    output_file = \"{directory}/{filepath}\".format(directory=PREDICT_OUPUT_DIR, filepath=f)\n",
        "\n",
        "    if not os.path.exists(PREDICT_OUPUT_DIR):\n",
        "            os.makedirs(PREDICT_OUPUT_DIR)\n",
        "\n",
        "    if exists(output_file):\n",
        "        print(\"File {} exists. Skipping...\".format(output_file))\n",
        "        continue\n",
        "\n",
        "    print(\"Predict: \", input_file, \"  >>  \", output_file)\n",
        "\n",
        "    classifier.predict(input_path=input_file, output_path=output_file,\n",
        "                       grids=PREDICT_GRIDS,\n",
        "                       batch_size=PREDICT_BATCH_SIZE)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "semantic_segmentation_rice_train.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
