{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"semantic_segmentation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_ArLtcoNXohm","colab_type":"text"},"source":["# Datasets\n","\n","We use Google Drive to share the data used for training the model and the model already trained. To add a shortcut to the location of the data in your Google Drive, follow these steps:    \n","\n","* Go to https://drive.google.com/drive/folders/1EPfe4G6Y32c6eTrM6gnTjxr7KUlrGwAt?usp=sharing\n","* Click in \"MAPBIOMAS-PUBLIC\" &#8594; \"Add Shortcut to Drive\" &#8594; \"My Drive\" &#8594; \"ADD SHORTCUT\""]},{"cell_type":"markdown","metadata":{"id":"z1GKkAiU3vbQ","colab_type":"text"},"source":["# Mount Google Drive\n","\n","After adding the shortcut to the data in your Google Drive, the next step is to mount a Google Drive volume on Google Colab."]},{"cell_type":"code","metadata":{"id":"Bt_Mg55M3tfS","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gy2UEd0xzKiX","colab_type":"code","colab":{}},"source":["!du -h -d 3 /content/drive/My\\ Drive/MAPBIOMAS-PUBLIC/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jXdiYWB546UX","colab_type":"text"},"source":["Information about directories and files:\n","\n","\n","* collection_5/center_pivot_irrigation/train &#8594; contains images ending in \"_mosaic.tif\", with 3 bands, and images ending in \"_labels.tif\", with 1 band. \n","For each image ending in \"_mosaic.tif\", which we use as an entry for the model, there is an image with the same prefix, but ending in \"_labels.tif\" containing the ground truth used to adjust the model;\n","\n","* collection_5/center_pivot_irrigation/test &#8594; follows the same structure as before, but with images that were used to test the model after the training process;\n","\n","* collection_5/center_pivot_irrigation/predict &#8594; example image that we can use, after training the model or using our trained model, to map the central pivot irrigation systems;\n","\n","* collection_5/center_pivot_irrigation/logs &#8594; trained model and log files generated in the training process."]},{"cell_type":"markdown","metadata":{"id":"aFa0jBMnWEIR","colab_type":"text"},"source":["# Check GPU\n","\n","We recommend that the entire model and classification training process be done using some of the GPUs available from Google Colab."]},{"cell_type":"code","metadata":{"id":"pmsT7NZ0YWHC","colab_type":"code","colab":{}},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5T7SsB0sFHZo"},"source":["# Install Requirements"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GdcHJiRBEiv4","colab":{}},"source":["#Step 1\n","!apt-get update\n","#Step 2\n","!apt-get install libgdal-dev -y\n","#Step 3\n","!apt-get install python-gdal -y"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mV6wHkfjIoas","colab_type":"text"},"source":["# Settings"]},{"cell_type":"markdown","metadata":{"id":"kBtLKOWelB5h","colab_type":"text"},"source":["## Center Pivot Irrigation Systems"]},{"cell_type":"code","metadata":{"id":"OPsmQ3RflGco","colab_type":"code","colab":{}},"source":["CHIP_SIZE = 256\n","CHANNELS = 3\n","LABELS = [0, 1]\n","SPATIAL_SCALE = 30\n","PROJECTION = 3857\n","\n","# Build Datasets\n","GRIDS = 1\n","ROTATE = True\n","FLIP = False\n","\n","TRAIN_VALIDATION_DIR = \"/content/drive/My Drive/MAPBIOMAS-PUBLIC/collection_5/center_pivot_irrigation/train\"\n","TEST_DIR = \"/content/drive/My Drive/MAPBIOMAS-PUBLIC/collection_5/center_pivot_irrigation/test\"\n","TRAIN_PATH = \"/content/train.h5\"\n","VALIDATION_PATH = \"/content/validation.h5\"\n","TEST_PATH = \"/content/test.h5\"\n","\n","# Train model\n","TRAIN_BATCH_SIZE = 20\n","TRAIN_EPOCHS = 50\n","\n","# Predict images\n","# PREDICT_INPUT_DIR = \"/content/drive/My Drive/MAPBIOMAS-PUBLIC/collection_5/center_pivot_irrigation/predict\"\n","PREDICT_INPUT_DIR = \"/content/drive/My Drive/MAPBIOMAS-PRIVATE\"\n","PREDICT_OUPUT_DIR = \"/content/drive/My Drive/MAPBIOMAS-PRIVATE/RESULTS\"\n","PREDICT_CHIP_SIZE = 1024\n","PREDICT_GRIDS = 3\n","PREDICT_BATCH_SIZE = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pOI--hdBCil3","colab_type":"text"},"source":["If you want to train a new model, you must run the following code snippet."]},{"cell_type":"code","metadata":{"id":"97VWhc-1RK5s","colab_type":"code","colab":{}},"source":["MODEL_DIR = \"/content/drive/My Drive/MAPBIOMAS-PRIVATE/logs\"\n","TRAIN_NEW_MODEL = True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N9ZOBj9tQxle","colab_type":"text"},"source":["If you want to use the model trained by us, just to perform the classification process, you must execute the code below. \n","\n","As the directory where the trained model will be published in read-only mode, if you execute this code snippet and try to retrain the model, you will receive an error indicating that Google Colab is unable to save the new trained model."]},{"cell_type":"code","metadata":{"id":"zWWAztLXQ9yG","colab_type":"code","colab":{}},"source":["MODEL_DIR = \"/content/drive/My Drive/MAPBIOMAS-PUBLIC/collection_5/center_pivot_irrigation/logs\"\n","TRAIN_NEW_MODEL = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Df9erxjKFAPm"},"source":["# Image Utils"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pS9aROwLE1LN","colab":{}},"source":["import gc\n","import os\n","\n","import h5py\n","import numpy as np\n","from osgeo import gdal, osr\n","from skimage.transform import resize, rotate\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","from tqdm import tqdm\n","\n","\n","def load_file(path, norm=False):\n","    original_source = gdal.Open(path)\n","    new_source = reproject_dataset(original_source,\n","                                   pixel_spacing=SPATIAL_SCALE,\n","                                   epsg_to=PROJECTION)\n","\n","    if not new_source is None:\n","        bands = []\n","        for index in range(1, new_source.RasterCount + 1):\n","            band = new_source.GetRasterBand(index).ReadAsArray()\n","            if norm:\n","                band = normalize(band)\n","            bands.append(band)\n","\n","        image = np.dstack(bands)\n","\n","        return original_source, new_source, image\n","    else:\n","        return original_source, new_source, None\n","\n","def normalize(image):\n","    image_max = float(np.max(image))\n","    image_min = float(np.min(image))\n","    normalized = (image - image_min) / (image_max - image_min)\n","    return normalized\n","\n","\n","def get_rotate(image):\n","    images = []\n","    for rot in [90, 180, 270]:\n","        image_rotate = rotate(image, rot, preserve_range=True)\n","        images.append(image_rotate)\n","    return images\n","\n","def get_flip(image):\n","    horizontal_flip = image[:, ::-1]\n","    vertical_flip = image[::-1, :]\n","    return [horizontal_flip, vertical_flip]\n","\n","def make_dataset(filename, width, height, channels):\n","    dataset = h5py.File(filename, 'w')\n","    x_data = dataset.create_dataset(\"x\", (0, width, height, channels), 'f',\n","                                    maxshape=(None, width, height, channels),\n","                                    chunks=True)\n","    y_data = dataset.create_dataset(\"y\", (0, width, height, 1), 'f',\n","                                    maxshape=(None, width, height, 1),\n","                                    chunks=True)\n","    return dataset, x_data, y_data\n","\n","def save_dataset(X, y, output_path, chip_size, channels):\n","    if os.path.isfile(output_path):\n","        dataset, x_data, y_data = load_dataset(output_path)\n","    else:\n","        dataset, x_data, y_data = make_dataset(output_path, chip_size,\n","                                               chip_size, channels)\n","\n","    length = len(X)\n","\n","    x_data_size = x_data.len()\n","    y_data_size = y_data.len()\n","\n","    x_data.resize((x_data_size + length, chip_size, chip_size, channels))\n","    y_data.resize((y_data_size + length, chip_size, chip_size, 1))\n","\n","    print(\"Saving dataset...\")\n","\n","    for index in tqdm(iterable=range(length), miniters=10, unit=\" samples\"):\n","        x_data[x_data_size + index] = X[index]\n","        y_data[y_data_size + index] = y[index]\n","\n","    dataset.close()\n","\n","def load_dataset(dataset, read_only=False):\n","    if read_only:\n","        dataset = h5py.File(dataset, 'r')\n","    else:\n","        dataset = h5py.File(dataset, 'r+')\n","    \n","    x_data = dataset[\"x\"]\n","    y_data = dataset[\"y\"]\n","\n","    return dataset, x_data, y_data\n","\n","def chip_is_empty(chip):\n","    labels_unique = np.unique(chip)\n","    return 0 in labels_unique and len(labels_unique) == 1\n","\n","\n","def generate_dataset(image_path, labels_path, chip_size, channels, \n","                     grids=1, allow_empty_chip=False, rotate=False, flip=False):\n","    _, _, image_data = load_file(image_path, norm=True)\n","    _, _, image_labels = load_file(labels_path)\n","\n","    image_labels = resize(image_labels,\n","                          (image_data.shape[0], image_data.shape[1]),\n","                          preserve_range=True, anti_aliasing=True).astype(np.int8)\n","\n","    image = np.dstack([image_data, image_labels])\n","\n","    X_set = []\n","    y_set = []\n","    for step in get_grids(grids, chip_size):\n","        for (x, y, window, dimension) in sliding_window(image,\n","                                                        step[\"steps\"],\n","                                                        step[\"chip_size\"],\n","                                                        (chip_size,\n","                                                         chip_size)):\n","\n","            train = np.array(window[:, :, : channels], dtype=np.float16)\n","            labels = np.array(window[:, :, -1:], dtype=np.int8)\n","\n","            if chip_is_empty(labels) and not allow_empty_chip:\n","                continue\n","\n","            raw_image = np.dstack([train, labels])\n","            images_daugmentation = [raw_image]\n","\n","            if rotate:\n","                images_rotate = get_rotate(raw_image)\n","                images_daugmentation.extend(images_rotate)\n","\n","            if flip:\n","                images_flip = []\n","                for im in images_daugmentation:\n","                    images_flip.extend(get_flip(im))\n","                images_daugmentation.extend(images_flip)\n","\n","            X_group = []\n","            Y_group = []\n","\n","            for i in images_daugmentation:\n","                new_train = np.array(i[:, :, :channels], dtype=np.float16)\n","                new_labels = np.array(i[:, :, -1:], dtype=np.int8)\n","\n","                np.clip(new_labels, 0, None, out=new_labels)\n","                \n","                X_group.append(new_train)\n","                Y_group.append(new_labels)\n","\n","            X_set.append(X_group)\n","            y_set.append(Y_group)\n","\n","        X_set = np.array(X_set)\n","        y_set = np.array(y_set)\n","\n","        yield X_set, y_set\n","\n","\n","def generate_train_validation_dataset(image_path, labels_path, \n","                                      train_path, validation_path, \n","                                      chip_size, \n","                                      channels=1, \n","                                      grids=1, \n","                                      allow_empty_chip=False, \n","                                      rotate=False, flip=False):\n","    \n","    for X_set, y_set in generate_dataset(image_path, labels_path, \n","                                    chip_size=chip_size,\n","                                    channels=channels, \n","                                    grids=grids, \n","                                    allow_empty_chip=allow_empty_chip, \n","                                    rotate=rotate, \n","                                    flip=flip):\n","        \n","        if len(X_set) >= 5:\n","            X_train, X_val, y_train, y_val = train_test_split(X_set, y_set,\n","                                                        test_size=0.25,\n","                                                        random_state=1)\n","\n","            X_train =  np.array([item for sublist in X_train for item in sublist])\n","            y_train =  np.array([item for sublist in y_train for item in sublist])\n","\n","            X_val =  np.array([item for sublist in X_val for item in sublist])\n","            y_val =  np.array([item for sublist in y_val for item in sublist])\n","\n","            save_dataset(X_train, y_train, train_path, chip_size, channels)\n","            save_dataset(X_val, y_val, validation_path, chip_size, channels)\n","\n","def generate_test_dataset(image_path, labels_path, test_path,\n","                                      chip_size=None, \n","                                      channels=None, grids=1, \n","                                      allow_empty_chip=False, \n","                                      rotate=False, flip=False, *args):\n","    \n","    for X_set, y_set in generate_dataset(image_path, labels_path, \n","                                    chip_size=chip_size,\n","                                    channels=channels, \n","                                    grids=grids, \n","                                    allow_empty_chip=allow_empty_chip, \n","                                    rotate=rotate, \n","                                    flip=flip):\n","\n","        X_test =  np.array([item for sublist in X_set for item in sublist])\n","        y_test =  np.array([item for sublist in y_set for item in sublist])\n","\n","        save_dataset(X_test, y_test, test_path, chip_size, channels)\n","\n","def sliding_window(image, step, chip_size, chip_resize):\n","    # slide a chip across the image\n","    step_cols = int(step[0])\n","    step_rows = int(step[1])\n","\n","    cols = image.shape[1]\n","    rows = image.shape[0]\n","\n","    chip_size_cols = chip_size[0]\n","    chip_size_rows = chip_size[1]\n","\n","    chip_resize_cols = chip_resize[0]\n","    chip_resize_rows = chip_resize[1]\n","\n","    for y in range(0, rows, step_rows):\n","        for x in range(0, cols, step_cols):\n","\n","            origin_x = x\n","            origin_y = y\n","\n","            if (origin_y + chip_size_rows) > rows:\n","                origin_y = rows - chip_size_rows\n","\n","            if (origin_x + chip_size_cols) > cols:\n","                origin_x = cols - chip_size_cols\n","\n","            chip = image[origin_y:origin_y + chip_size_rows,\n","                   origin_x: origin_x + chip_size_cols]\n","\n","            original_shape = chip.shape\n","\n","            if chip.shape != (chip_resize_cols, chip_resize_rows):\n","                chip = resize(chip,\n","                              (chip_resize_cols, chip_resize_rows),\n","                              preserve_range=True,\n","                              anti_aliasing=True).astype(np.float16)\n","\n","            yield (origin_x, origin_y, chip, original_shape)\n","\n","\n","def get_window(matrix, x, y, width, height):\n","    return matrix[y:y + height, x:x + width]\n","\n","\n","def set_window(matrix, x, y, new_matrix):\n","    for i_index, i in enumerate(range(y, y + new_matrix.shape[0])):\n","        for j_index, j in enumerate(range(x, x + new_matrix.shape[1])):\n","            matrix[i][j] = new_matrix[i_index][j_index]\n","\n","\n","def transform_labels(labels_array, labels):\n","    lb = preprocessing.LabelBinarizer()\n","    lb.fit(labels)\n","    new_labels_array = []\n","    for ix, l in enumerate(labels_array):\n","        flat_labels = l.reshape((l.shape[0] * l.shape[1],))\n","        transformed_flat_labels = lb.transform(flat_labels)\n","        new_labels_array.append(transformed_flat_labels.reshape(\n","            (l.shape[0], l.shape[1], len(labels))))\n","\n","    new_labels_array = np.array(new_labels_array)\n","    return new_labels_array\n","\n","\n","def get_grids(grids, chip_size):\n","    grids_dict = {\n","        1: [\n","            {\"steps\": (chip_size, chip_size),\n","             \"chip_size\": (chip_size, chip_size)}\n","        ],\n","        2: [\n","            {\"steps\": (int(chip_size * 0.5), int(chip_size * 0.5)),\n","             \"chip_size\": (chip_size, chip_size)},\n","        ],\n","        3: [\n","            {\"steps\": (int(chip_size * 0.9), int(chip_size * 0.9)),\n","             \"chip_size\": (chip_size, chip_size)},\n","        ]\n","    }\n","\n","    return grids_dict[grids]\n","\n","\n","def reproject_dataset(g, pixel_spacing=30., epsg_to=3857):\n","    osng = osr.SpatialReference()\n","    osng.ImportFromEPSG(epsg_to)\n","\n","    wkt = g.GetProjection()\n","    wgs84 = osr.SpatialReference()\n","    wgs84.ImportFromWkt(wkt)\n","\n","    tx = osr.CoordinateTransformation(wgs84, osng)\n","    # Up to here, all  the projection have been defined, as well as a\n","    # transformation from the from to the  to :)\n","\n","    # Get the Geotransform vector\n","    geo_t = g.GetGeoTransform()\n","    x_size = g.RasterXSize  # Raster xsize\n","    y_size = g.RasterYSize  # Raster ysize\n","    # Work out the boundaries of the new dataset in the target projection\n","    (ulx, uly, ulz) = tx.TransformPoint(geo_t[0], geo_t[3])\n","    (lrx, lry, lrz) = tx.TransformPoint(geo_t[0] + geo_t[1] * x_size, \\\n","                                        geo_t[3] + geo_t[5] * y_size)\n","\n","    # Now, we create an in-memory raster\n","    mem_drv = gdal.GetDriverByName('MEM')\n","    # The size of the raster is given the new projection and pixel spacing\n","    # Using the values we calculated above. Also, setting it to store one band\n","    # and to use Float32 data type.\n","    dest = mem_drv.Create('', int((lrx - ulx) / pixel_spacing), \\\n","                          int((uly - lry) / pixel_spacing), g.RasterCount,\n","                          g.GetRasterBand(1).DataType)\n","    # Calculate the new geotransform\n","    new_geo = (ulx, pixel_spacing, geo_t[2], \\\n","               uly, geo_t[4], -pixel_spacing)\n","    # Set the geotransform\n","    dest.SetGeoTransform(new_geo)\n","    dest.SetProjection(osng.ExportToWkt())\n","    # Perform the projection/resampling\n","    res = gdal.ReprojectImage(g, dest, \\\n","                              wgs84.ExportToWkt(), osng.ExportToWkt(), \\\n","                              gdal.GRA_NearestNeighbour)\n","    return dest\n","\n","\n","\n","def save_results(original_dataset, reprojected_dataset, image, output_path):\n","    mem_dataset = reprojected_dataset \\\n","        .GetDriver() \\\n","        .Create(output_path, image.shape[1], image.shape[0], 1, gdal.GDT_Int16)\n","\n","    mem_dataset.SetGeoTransform(reprojected_dataset.GetGeoTransform())\n","    mem_dataset.SetProjection(reprojected_dataset.GetProjection())\n","    mem_dataset.GetRasterBand(1) \\\n","        .WriteArray(image.reshape((image.shape[0], image.shape[1])), 0, 0)\n","    mem_dataset.FlushCache()\n","\n","    original_epsg = int(osr \\\n","                        .SpatialReference(wkt=original_dataset.GetProjection()) \\\n","                        .GetAttrValue('AUTHORITY', 1))\n","\n","    output_dataset = reproject_dataset(mem_dataset,\n","                                       SPATIAL_SCALE,\n","                                       original_epsg)\n","\n","    original_dataset.GetDriver().CreateCopy(output_path,\n","                                            output_dataset,\n","                                            options=['COMPRESS=LZW',\n","                                                     'TFW=YES'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UOCNbbIp03Df"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"HKh4wgFDpK9e","colab_type":"text"},"source":["## Evaluation Metric"]},{"cell_type":"code","metadata":{"id":"DKBbhFD7yjy2","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.keras import backend as K\n","\n","def mean_iou(y_true, y_pred):\n","    prec = []\n","    for t in np.arange(0.5, 1.0, 0.05):\n","        y_pred = K.cast(K.greater(y_pred, t), dtype='float32')\n","        inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)\n","        union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter\n","        acc = K.mean((inter + K.epsilon()) / (union + K.epsilon()))\n","        prec.append(acc)\n","    return  K.mean(tf.convert_to_tensor(prec))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_b458qR8pRMU","colab_type":"text"},"source":["## U-Net"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"M9uL77bj08t6","colab":{}},"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, \\\n","    Conv2DTranspose, concatenate, BatchNormalization, Activation\n","\n","\n","def conv(n_filters, kernel_size, activation='elu', inputs=None):\n","    net = Conv2D(n_filters, kernel_size, activation=None, \\\n","                 kernel_initializer='he_normal', padding='same') (inputs) \n","    net = BatchNormalization()(net)\n","    net = Activation(activation)(net)\n","    return net\n","\n","def transpose(n_filters, kernel_size, activation='elu', inputs=None):\n","    net = Conv2DTranspose(n_filters, kernel_size, activation=None, \n","                          strides=(2, 2), padding='same', \n","                          kernel_initializer='he_normal') (inputs)\n","    net = BatchNormalization()(net)\n","    net = Activation(activation)(net)\n","    return net\n","\n","def model_fn(input_shape, n_filters=64, labels=[]):\n","    print(input_shape, labels)\n","    inputs = keras.Input(input_shape)\n","\n","    c1 = conv(n_filters * 1, (3, 3), inputs=inputs)\n","    c1 = conv(n_filters * 1, (3, 3), inputs=c1)\n","    p1 = MaxPooling2D((2, 2)) (c1)\n","    p1 = Dropout(0.25) (p1)\n","\n","    c2 = conv(n_filters * 2, (3, 3), inputs=p1)\n","    c2 = conv(n_filters * 2, (3, 3), inputs=c2)\n","    p2 = MaxPooling2D((2, 2)) (c2)\n","    p2 = Dropout(0.25) (p2)\n","\n","    c3 = conv(n_filters * 4, (3, 3), inputs=p2)\n","    c3 = conv(n_filters * 4, (3, 3), inputs=c3)\n","    p3 = MaxPooling2D((2, 2)) (c3)\n","    p3 = Dropout(0.5) (p3)\n","\n","    c4 = conv(n_filters * 8, (3, 3), inputs=p3)\n","    c4 = conv(n_filters * 8, (3, 3), inputs=c4)\n","    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n","    p4 = Dropout(0.5) (p4)\n","\n","    c5 = conv(n_filters * 16, (3, 3), inputs=p4)\n","    c5 = conv(n_filters * 16, (3, 3), inputs=c5)\n","    c5 = Dropout(0.5) (c5)\n","\n","    u6 = transpose(n_filters * 8, (2, 2), inputs=c5)\n","    u6 = concatenate([u6, c4])\n","    c6 = conv(n_filters * 8, (2, 2), inputs=u6)\n","    c6 = conv(n_filters * 8, (2, 2), inputs=c6)\n","    c6 = Dropout(0.5) (c6)\n","    \n","    u7 = transpose(n_filters * 4, (2, 2), inputs=c6)\n","    u7 = concatenate([u7, c3])\n","    c7 = conv(n_filters * 4, (2, 2), inputs=u7)\n","    c7 = conv(n_filters * 4, (2, 2), inputs=c7)\n","    c7 = Dropout(0.5) (c7)\n","\n","    u8 = transpose(n_filters * 2, (2, 2), inputs=c7)\n","    u8 = concatenate([u8, c2])\n","    c8 = conv(n_filters * 2, (2, 2), inputs=u8)\n","    c8 = conv(n_filters * 2, (2, 2), inputs=c8)\n","    c8 = Dropout(0.25) (c8)\n","    \n","    u9 = transpose(n_filters * 1, (2, 2), inputs=c8)\n","    u9 = concatenate([u9, c1], axis=3)\n","    c9 = conv(n_filters * 1, (2, 2), inputs=u9)\n","    c9 = conv(n_filters * 1, (2, 2), inputs=c9)\n","    c9 = Dropout(0.25) (c9)\n","    \n","    if len(labels) > 2:\n","        outputs = tf.keras.layers.Conv2D(len(labels), 1, 1, activation='softmax')(c9)\n","        loss_function = 'categorical_crossentropy'\n","        metrics = ['categorical_accuracy']\n","    else:\n","        outputs = conv(1, (1, 1), activation='sigmoid', inputs=c9)\n","        loss_function = 'binary_crossentropy'\n","        metrics = [mean_iou]\n","\n","    model = keras.Model(inputs=inputs, outputs=outputs)\n","    optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001)\n","    model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics)\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oyfS7rI82Dj4"},"source":["# Classifier"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ngmo5JVC2DzF","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","from osgeo import gdal\n","from tqdm import tqdm\n","\n","\n","class Classifier(object):\n","    def __init__(self, chip_size, channels, model_dir, labels):\n","        self.__chip_size = chip_size\n","        self.__channels = channels\n","        self.__labels = labels\n","        self.__model = model_fn((chip_size, chip_size, channels), labels=labels)\n","        self.__checkpoints = []\n","\n","        if not os.path.exists(model_dir):\n","            os.makedirs(model_dir)\n","\n","        self.load_model(model_dir)\n","        self.load_callbacks(model_dir)\n","\n","    def load_model(self, model_dir):\n","        latest = tf.train.latest_checkpoint(model_dir)\n","\n","        if latest:\n","            print(\"Loading model....\")\n","            self.__model.load_weights(latest)\n","\n","        print(\"Model loaded!\")\n","        self.__model.summary()\n","\n","    def load_callbacks(self, model_dir):\n","        checkpoint_path = \"{dir}/model.ckpt\".format(dir=model_dir)\n","\n","        cp_callback = tf.keras.callbacks.ModelCheckpoint(\n","            filepath=checkpoint_path,\n","            save_weights_only=True,\n","            save_best_only=True)\n","\n","        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=model_dir)\n","\n","        self.__callbacks = [cp_callback, tensorboard_callback]\n","\n","\n","    def train(self, input_train, input_validation, epochs, batch_size):\n","        train_dataset, train_data, train_labels = load_dataset(input_train,\n","                                                            read_only=True)\n","        validation_dataset, validation_data, validation_labels = load_dataset(\n","            input_validation, read_only=True)\n","\n","        train_images = np.asarray(train_data, dtype=np.float16)\n","        train_labels = np.asarray(train_labels, dtype=np.int8)\n","\n","        validation_images = np.asarray(validation_data, dtype=np.float16)\n","        validation_labels = np.asarray(validation_labels, dtype=np.int8)\n","\n","        if len(self.__labels) > 2:\n","            train_labels = transform_labels(train_labels, self.__labels)\n","            validation_labels = transform_labels(validation_labels,\n","                                                 self.__labels)\n","\n","        print(train_images.shape)\n","        print(train_labels.shape)\n","\n","        print(\"\\nTrain: {train_size}\\n Validation: {validation_size}\".format(\n","            train_size=train_images.shape[0], \n","            validation_size=validation_images.shape[0]))\n","\n","        self.__model.fit(x=train_images,\n","                         y=train_labels,\n","                         validation_data=(validation_images, validation_labels),\n","                         epochs=epochs,\n","                         batch_size=batch_size,\n","                         verbose=1,\n","                         callbacks=self.__callbacks,\n","                         shuffle=True)\n","        \n","        train_dataset.close()\n","        validation_dataset.close()\n","\n","    def evaluate(self, input_test, batch_size):\n","        test_file, test_data, test_labels = load_dataset(input_test,\n","                                                         read_only=True)\n","\n","        test_data = np.asarray(test_data, dtype=np.float16)\n","        test_labels = np.asarray(test_labels, dtype=np.int8)\n","\n","        test_results = self.__model.evaluate(test_data,\n","                                             test_labels,\n","                                             batch_size=batch_size)\n","\n","        print('test loss, test acc:', test_results)\n","\n","    def predict(self, input_path, output_path, grids, batch_size):\n","        original_dataset, input_dataset, image = load_file(input_path,\n","                                                           norm=True)\n","\n","        image = image[:, :, : self.__channels]\n","\n","        predicted_image = np.zeros((image.shape[0], image.shape[1]),\n","                                   dtype=np.int8)\n","\n","        grids = get_grids(grids, self.__chip_size)\n","\n","        for step in grids:\n","            batch = []\n","            windows = sliding_window(image, step[\"steps\"], step[\"chip_size\"],\n","                                     (self.__chip_size, self.__chip_size))\n","\n","            for (x, y, chip, original_dimensions) in tqdm(iterable=windows,\n","                                                          miniters=10,\n","                                                          unit=\" windows\"):\n","\n","                normalized_chip = normalize(chip)\n","\n","                batch.append({\n","                    \"chip\": normalized_chip,\n","                    \"x\": x,\n","                    \"y\": y,\n","                    \"dimensions\": original_dimensions\n","                })\n","\n","                if len(batch) >= batch_size:\n","                    chips = []\n","                    positions = []\n","                    dimensions = []\n","\n","                    for b in batch:\n","                        chips.append(b.get(\"chip\"))\n","                        positions.append((b.get(\"x\"), b.get(\"y\")))\n","                        dimensions.append(b.get(\"dimensions\"))\n","\n","                    chips = np.array(chips, dtype=np.float16)\n","\n","                    pred = self.__model.predict(chips, batch_size=batch_size)\n","\n","                    for chip, position, dimension, predict in zip(chips,\n","                                                                  positions,\n","                                                                  dimensions,\n","                                                                  pred):\n","\n","                        if len(self.__labels) > 2:\n","                            predict = np.array(tf.math.argmax(predict, axis=2))\n","                        else:\n","                            predict[predict > 0.5] = 1\n","                            predict[predict <= 0.5] = 0\n","\n","                        predict = resize(predict, (dimension[0], dimension[1]),\n","                                         preserve_range=True,\n","                                         anti_aliasing=True).astype(np.int8)\n","\n","                        predict = predict.reshape(\n","                            (predict.shape[0], predict.shape[1]))\n","\n","                        predicted = get_window(predicted_image,\n","                                               position[0],\n","                                               position[1],\n","                                               predict.shape[1],\n","                                               predict.shape[0])\n","\n","                        if predict.shape != predicted.shape:\n","                            raise Exception(\"predict.shape != predicted.shape\")\n","\n","                        if len(self.__labels) > 2:\n","                            set_window(predicted_image, position[0],\n","                                       position[1], predict)\n","                        else:\n","                            set_window(predicted_image, position[0],\n","                                       position[1], np.add(predict, predicted))\n","\n","                    batch = []\n","\n","            if len(self.__labels) == 2:\n","                predicted_image[predicted_image >= 1] = 1\n","                \n","            print(\"Saving results...\")\n","            save_results(original_dataset, input_dataset, predicted_image,\n","                      output_path)\n","            print(\"Finished!\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"G62gUubn1eme"},"source":["# Train Model"]},{"cell_type":"markdown","metadata":{"id":"DydlXKwXKt1n","colab_type":"text"},"source":["## Build Train and Validation datasets"]},{"cell_type":"code","metadata":{"id":"qzuSbSOAJtlq","colab_type":"code","colab":{}},"source":["if TRAIN_NEW_MODEL:\n","    import glob\n","\n","    images = [f for f in glob.glob(TRAIN_VALIDATION_DIR + \"/*mosaic.tif\", recursive=True)]\n","\n","    if len(images) == 0:\n","        print(\"No samples found.\")\n","\n","    for image_path in images:\n","        labels_path = image_path.replace(\"mosaic\", \"labels\")\n","        print(image_path)\n","        print(labels_path)\n","        generate_train_validation_dataset(\n","            image_path=image_path,\n","            labels_path=labels_path,\n","            train_path=TRAIN_PATH,\n","            validation_path=VALIDATION_PATH,\n","            chip_size=CHIP_SIZE,\n","            channels=CHANNELS,\n","            grids=GRIDS,\n","            rotate=ROTATE\n","        )\n","else:\n","    print(\"Please, go to the settings and execute the code snippet indicated for training a new model.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FIhJy8c7Kwgn","colab_type":"text"},"source":["## Plot Images"]},{"cell_type":"code","metadata":{"id":"cAGlCBcZK5Ay","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","import cv2\n","import random\n","\n","\n","def plot_figures(figures, nrows = 1, ncols=1):\n","    \"\"\"Plot a dictionary of figures.\n","\n","    Parameters\n","    ----------\n","    figures : <title, figure> dictionary\n","    ncols : number of columns of subplots wanted in the display\n","    nrows : number of rows of subplots wanted in the figure\n","    \"\"\"\n","\n","    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=(19, 10))\n","    for ind,title in zip(range(len(figures)), figures):\n","        image = figures[title]\n","        if image.shape[2] >= 3:\n","            image = image[:, : , :3]\n","            axeslist.ravel()[ind].imshow(image, vmin=0.1, vmax=0.4)\n","        else:\n","            image = image.reshape((image.shape[0], image.shape[1]))\n","            axeslist.ravel()[ind].imshow(image)\n","        axeslist.ravel()[ind].set_title(title)\n","        axeslist.ravel()[ind].set_axis_off()\n","    plt.tight_layout() # optional\n","\n","figures = {}\n","\n","dataset, x, y = load_dataset(TRAIN_PATH, read_only=True)\n","\n","ids = []\n","\n","samples = 4\n","\n","for i in range(0, samples):\n","    id = random.randint(0,x.shape[0])\n","    figures['img_x'+ str(i)] = x[id]\n","    figures['img_y'+ str(i)] = y[id]\n","\n","plot_figures(figures, 2, samples)\n","dataset.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FQXkIsGIk8f5","colab_type":"text"},"source":["## Run Train"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MZZgZqYB1fl9","colab":{}},"source":["if TRAIN_NEW_MODEL:\n","    classifier = Classifier(chip_size=CHIP_SIZE,\n","                            channels=CHANNELS,\n","                            model_dir=MODEL_DIR,\n","                            labels=LABELS)\n","\n","    classifier.train(\n","        input_train=TRAIN_PATH,\n","        input_validation=VALIDATION_PATH,\n","        epochs=TRAIN_EPOCHS,\n","        batch_size=TRAIN_BATCH_SIZE\n","    )\n","else:\n","    print(\"Please, go to the settings and execute the code snippet indicated for training a new model.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yZKPCpCwOeBs","colab_type":"text"},"source":["# Evaluate Model"]},{"cell_type":"markdown","metadata":{"id":"i6SPQLaRS_0L","colab_type":"text"},"source":["## Build Test dataset"]},{"cell_type":"code","metadata":{"id":"veChduIjTC7I","colab_type":"code","colab":{}},"source":["import glob\n","\n","images = [f for f in glob.glob(TEST_DIR + \"/*mosaic.tif\", recursive=True)]\n","\n","if len(images) == 0:\n","    print(\"No test found.\")\n","\n","for image_path in images:\n","    labels_path = image_path.replace(\"mosaic\", \"labels\")\n","    print(image_path)\n","    print(labels_path)\n","    generate_test_dataset(\n","        image_path=image_path,\n","        labels_path=labels_path,\n","        test_path=TEST_PATH,\n","        chip_size=CHIP_SIZE,\n","        channels=CHANNELS,\n","        grids=1,\n","        allow_empty_chip=True\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QQrxITsHlyZ_","colab_type":"text"},"source":["## Run Evaluation"]},{"cell_type":"code","metadata":{"id":"eoig24NpOgpw","colab_type":"code","colab":{}},"source":["classifier = Classifier(chip_size=CHIP_SIZE,\n","                        channels=CHANNELS,\n","                        model_dir=MODEL_DIR,\n","                        labels=LABELS)\n","\n","classifier.evaluate(\n","    input_test=TEST_PATH,\n","    batch_size=BATCH_SIZE\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CQRqOn292cJs"},"source":["# Predict Images"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cDcbK0cn2cfc","colab":{}},"source":["from os import listdir\n","from os.path import isfile, join, sep, exists\n","\n","classifier = Classifier(chip_size=PREDICT_CHIP_SIZE,\n","                        channels=CHANNELS,\n","                        model_dir=MODEL_DIR,\n","                        labels=LABELS)\n","\n","files = [f for f in listdir(PREDICT_INPUT_DIR) if\n","         isfile(join(PREDICT_INPUT_DIR, f))]\n","\n","if len(files) == 0:\n","    print(\"No file found.\")\n","\n","for f in files:\n","    print(\"File:\", f)\n","    input_file = \"{directory}/{filepath}\".format(directory=PREDICT_INPUT_DIR, filepath=f)\n","\n","    output_file = \"{directory}/{filepath}\".format(directory=PREDICT_OUPUT_DIR, filepath=f)\n","\n","    if not os.path.exists(PREDICT_OUPUT_DIR):\n","            os.makedirs(PREDICT_OUPUT_DIR)\n","\n","    if exists(output_file):\n","        print(\"File {} exists. Skipping...\".format(output_file))\n","        continue\n","\n","    print(\"Predict: \", input_file, \"  >>  \", output_file)\n","\n","    classifier.predict(input_path=input_file, output_path=output_file,\n","                       grids=PREDICT_GRIDS,\n","                       batch_size=PREDICT_BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nkQtBl5DaWOt","colab_type":"text"},"source":["# Do it yourself\n","\n","What do you think about mapping central pivot irrigation systems anywhere in the world?\n","\n","First, you will need to build an image that will be used as an input to our mapping model. To build this image, you can use this [script](https://code.earthengine.google.com/cac251ac4de93c1c09fcbcb8adf00d7a) that must be run on the platform [Google Earth Engine](https://earthengine.google.com/).\n","\n","Following the instructions in the script, it will export an image into the MAPBIOMAS-PRIVATE directory on your Google Drive.\n","\n","With the image saved, you need to change the variable **PREDICT_INPUT_DIR** in the section **Settings** for the value: \n","\n","PREDICT_INPUT_DIR = \"/content/drive/My Drive/MAPBIOMAS-PRIVATE\"\n","\n","After changing the variable value, just run the sections again\n"," **Settings** and **Predict Images** and get the mapping result in your Google Drive.\n","\n"]}]}