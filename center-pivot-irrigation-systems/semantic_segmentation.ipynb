{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "semantic_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oyfS7rI82Dj4"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ArLtcoNXohm"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "We use Google Drive to share the data used for training the model and the model already trained. To add a shortcut to the location of the data in your Google Drive, follow these steps:    \n",
        "\n",
        "* Go to https://drive.google.com/drive/folders/1EPfe4G6Y32c6eTrM6gnTjxr7KUlrGwAt?usp=sharing\n",
        "* Click in \"MAPBIOMAS-PUBLIC\" &#8594; \"Add Shortcut to Drive\" &#8594; \"My Drive\" &#8594; \"ADD SHORTCUT\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1GKkAiU3vbQ"
      },
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "After adding the shortcut to the data in your Google Drive, the next step is to mount a Google Drive volume on Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt_Mg55M3tfS"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy2UEd0xzKiX"
      },
      "source": [
        "!du -h -d 3 /content/drive/My\\ Drive/MAPBIOMAS-PUBLIC/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXdiYWB546UX"
      },
      "source": [
        "Information about directories and files:\n",
        "\n",
        "\n",
        "* collection_5/center_pivot_irrigation/train &#8594; contains images ending in \"_mosaic.tif\", with 3 bands, and images ending in \"_labels.tif\", with 1 band. \n",
        "For each image ending in \"_mosaic.tif\", which we use as an entry for the model, there is an image with the same prefix, but ending in \"_labels.tif\" containing the ground truth used to adjust the model;\n",
        "\n",
        "* collection_5/center_pivot_irrigation/test &#8594; follows the same structure as before, but with images that were used to test the model after the training process;\n",
        "\n",
        "* collection_5/center_pivot_irrigation/predict &#8594; example image that we can use, after training the model or using our trained model, to map the central pivot irrigation systems;\n",
        "\n",
        "* collection_5/center_pivot_irrigation/logs &#8594; trained model and log files generated in the training process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFa0jBMnWEIR"
      },
      "source": [
        "# Check GPU\n",
        "\n",
        "We recommend that the entire model and classification training process be done using some of the GPUs available from Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmsT7NZ0YWHC"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "    print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "    print('and then re-execute this cell.')\n",
        "else:\n",
        "    print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T7SsB0sFHZo"
      },
      "source": [
        "# Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdcHJiRBEiv4"
      },
      "source": [
        "#Step 1\n",
        "!apt-get update\n",
        "#Step 2\n",
        "!apt-get install libgdal-dev -y\n",
        "#Step 3\n",
        "!apt-get install python-gdal -y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV6wHkfjIoas"
      },
      "source": [
        "# Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBtLKOWelB5h"
      },
      "source": [
        "## Center Pivot Irrigation Systems"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPsmQ3RflGco"
      },
      "source": [
        "CHIP_SIZE = 256\n",
        "CHANNELS = 3\n",
        "LABELS = [0, 1]\n",
        "SPATIAL_SCALE = 30\n",
        "PROJECTION = 3857\n",
        "\n",
        "# Build Datasets\n",
        "GRIDS = 1\n",
        "ROTATE = True\n",
        "FLIP = False\n",
        "\n",
        "TRAIN_VALIDATION_DIR = \"/content/drive/My Drive/MAPBIOMAS-PUBLIC/collection_5/center_pivot_irrigation/train\"\n",
        "TEST_DIR = \"/content/drive/My Drive/MAPBIOMAS-PUBLIC/collection_5/center_pivot_irrigation/test\"\n",
        "TRAIN_PATH = \"/content/train.h5\"\n",
        "VALIDATION_PATH = \"/content/validation.h5\"\n",
        "TEST_PATH = \"/content/test.h5\"\n",
        "\n",
        "# Train model\n",
        "TRAIN_BATCH_SIZE = 20\n",
        "TRAIN_EPOCHS = 50\n",
        "\n",
        "# Predict images\n",
        "PREDICT_INPUT_DIR = \"/content/drive/My Drive/MAPBIOMAS-PRIVATE\"\n",
        "PREDICT_OUPUT_DIR = \"/content/drive/My Drive/MAPBIOMAS-PRIVATE/RESULTS\"\n",
        "PREDICT_CHIP_SIZE = 1024\n",
        "PREDICT_GRIDS = 3\n",
        "PREDICT_BATCH_SIZE = 1\n",
        "\n",
        "# Load trained model\n",
        "MODEL_DIR = \"/content/drive/My Drive/MAPBIOMAS-PUBLIC/collection_5/center_pivot_irrigation/logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Df9erxjKFAPm"
      },
      "source": [
        "# Image Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS9aROwLE1LN"
      },
      "source": [
        "import gc\n",
        "import os\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "from osgeo import gdal, osr\n",
        "from skimage.transform import resize, rotate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def load_file(path, norm=False):\n",
        "    original_source = gdal.Open(path)\n",
        "    new_source = reproject_dataset(original_source,\n",
        "                                   pixel_spacing=SPATIAL_SCALE,\n",
        "                                   epsg_to=PROJECTION)\n",
        "\n",
        "    if not new_source is None:\n",
        "        bands = []\n",
        "        for index in range(1, new_source.RasterCount + 1):\n",
        "            band = new_source.GetRasterBand(index).ReadAsArray()\n",
        "            if norm:\n",
        "                band = normalize(band)\n",
        "            bands.append(band)\n",
        "\n",
        "        image = np.dstack(bands)\n",
        "\n",
        "        return original_source, new_source, image\n",
        "    else:\n",
        "        return original_source, new_source, None\n",
        "\n",
        "def normalize(image):\n",
        "    image_max = float(np.max(image))\n",
        "    image_min = float(np.min(image))\n",
        "    normalized = (image - image_min) / (image_max - image_min)\n",
        "    return normalized\n",
        "\n",
        "\n",
        "def get_rotate(image):\n",
        "    images = []\n",
        "    for rot in [90, 180, 270]:\n",
        "        image_rotate = rotate(image, rot, preserve_range=True)\n",
        "        images.append(image_rotate)\n",
        "    return images\n",
        "\n",
        "def get_flip(image):\n",
        "    horizontal_flip = image[:, ::-1]\n",
        "    vertical_flip = image[::-1, :]\n",
        "    return [horizontal_flip, vertical_flip]\n",
        "\n",
        "def make_dataset(filename, width, height, channels):\n",
        "    dataset = h5py.File(filename, 'w')\n",
        "    x_data = dataset.create_dataset(\"x\", (0, width, height, channels), 'f',\n",
        "                                    maxshape=(None, width, height, channels),\n",
        "                                    chunks=True)\n",
        "    y_data = dataset.create_dataset(\"y\", (0, width, height, 1), 'f',\n",
        "                                    maxshape=(None, width, height, 1),\n",
        "                                    chunks=True)\n",
        "    return dataset, x_data, y_data\n",
        "\n",
        "def save_dataset(X, y, output_path, chip_size, channels):\n",
        "    if os.path.isfile(output_path):\n",
        "        dataset, x_data, y_data = load_dataset(output_path)\n",
        "    else:\n",
        "        dataset, x_data, y_data = make_dataset(output_path, chip_size,\n",
        "                                               chip_size, channels)\n",
        "\n",
        "    length = len(X)\n",
        "\n",
        "    x_data_size = x_data.len()\n",
        "    y_data_size = y_data.len()\n",
        "\n",
        "    x_data.resize((x_data_size + length, chip_size, chip_size, channels))\n",
        "    y_data.resize((y_data_size + length, chip_size, chip_size, 1))\n",
        "\n",
        "    print(\"Saving dataset...\")\n",
        "    x_data[y_data_size:] = X\n",
        "    y_data[y_data_size:] = y\n",
        "\n",
        "    dataset.close()\n",
        "\n",
        "def load_dataset(dataset, read_only=False):\n",
        "    if read_only:\n",
        "        dataset = h5py.File(dataset, 'r')\n",
        "    else:\n",
        "        dataset = h5py.File(dataset, 'r+')\n",
        "    \n",
        "    x_data = dataset[\"x\"]\n",
        "    y_data = dataset[\"y\"]\n",
        "\n",
        "    return dataset, x_data, y_data\n",
        "\n",
        "def chip_is_empty(chip):\n",
        "    labels_unique = np.unique(chip)\n",
        "    return 0 in labels_unique and len(labels_unique) == 1\n",
        "\n",
        "\n",
        "def generate_dataset(image_path, labels_path, chip_size, channels, \n",
        "                     grids=1, allow_empty_chip=False, rotate=False, flip=False):\n",
        "    _, _, image_data = load_file(image_path, norm=True)\n",
        "    _, _, image_labels = load_file(labels_path)\n",
        "\n",
        "    image_labels = resize(image_labels,\n",
        "                          (image_data.shape[0], image_data.shape[1]),\n",
        "                          preserve_range=True, anti_aliasing=True).astype(np.int8)\n",
        "\n",
        "    image = np.dstack([image_data, image_labels])\n",
        "\n",
        "    X_set = []\n",
        "    y_set = []\n",
        "    for step in get_grids(grids, chip_size):\n",
        "        for (x, y, window, dimension) in sliding_window(image,\n",
        "                                                        step[\"steps\"],\n",
        "                                                        step[\"chip_size\"],\n",
        "                                                        (chip_size,\n",
        "                                                         chip_size)):\n",
        "\n",
        "            train = np.array(window[:, :, : channels], dtype=np.float16)\n",
        "            labels = np.array(window[:, :, -1:], dtype=np.int8)\n",
        "\n",
        "            if chip_is_empty(labels) and not allow_empty_chip:\n",
        "                continue\n",
        "\n",
        "            raw_image = np.dstack([train, labels])\n",
        "            images_daugmentation = [raw_image]\n",
        "\n",
        "            if rotate:\n",
        "                images_rotate = get_rotate(raw_image)\n",
        "                images_daugmentation.extend(images_rotate)\n",
        "\n",
        "            if flip:\n",
        "                images_flip = []\n",
        "                for im in images_daugmentation:\n",
        "                    images_flip.extend(get_flip(im))\n",
        "                images_daugmentation.extend(images_flip)\n",
        "\n",
        "            X_group = []\n",
        "            Y_group = []\n",
        "\n",
        "            for i in images_daugmentation:\n",
        "                new_train = np.array(i[:, :, :channels], dtype=np.float16)\n",
        "                new_labels = np.array(i[:, :, -1:], dtype=np.int8)\n",
        "\n",
        "                np.clip(new_labels, 0, None, out=new_labels)\n",
        "                \n",
        "                X_group.append(new_train)\n",
        "                Y_group.append(new_labels)\n",
        "\n",
        "            X_set.append(X_group)\n",
        "            y_set.append(Y_group)\n",
        "\n",
        "        X_set = np.array(X_set)\n",
        "        y_set = np.array(y_set)\n",
        "\n",
        "        yield X_set, y_set\n",
        "\n",
        "\n",
        "def generate_train_validation_dataset(image_path, labels_path, \n",
        "                                      train_path, validation_path, \n",
        "                                      chip_size, \n",
        "                                      channels=1, \n",
        "                                      grids=1, \n",
        "                                      allow_empty_chip=False, \n",
        "                                      rotate=False, flip=False):\n",
        "    \n",
        "    for X_set, y_set in generate_dataset(image_path, labels_path, \n",
        "                                    chip_size=chip_size,\n",
        "                                    channels=channels, \n",
        "                                    grids=grids, \n",
        "                                    allow_empty_chip=allow_empty_chip, \n",
        "                                    rotate=rotate, \n",
        "                                    flip=flip):\n",
        "        \n",
        "        if len(X_set) >= 5:\n",
        "            X_train, X_val, y_train, y_val = train_test_split(X_set, y_set,\n",
        "                                                        test_size=0.25,\n",
        "                                                        random_state=1)\n",
        "\n",
        "            X_train =  np.array([item for sublist in X_train for item in sublist])\n",
        "            y_train =  np.array([item for sublist in y_train for item in sublist])\n",
        "\n",
        "            X_val =  np.array([item for sublist in X_val for item in sublist])\n",
        "            y_val =  np.array([item for sublist in y_val for item in sublist])\n",
        "\n",
        "            save_dataset(X_train, y_train, train_path, chip_size, channels)\n",
        "            save_dataset(X_val, y_val, validation_path, chip_size, channels)\n",
        "\n",
        "def generate_test_dataset(image_path, labels_path, test_path,\n",
        "                                      chip_size=None, \n",
        "                                      channels=None, grids=1, \n",
        "                                      allow_empty_chip=False, \n",
        "                                      rotate=False, flip=False, *args):\n",
        "    \n",
        "    for X_set, y_set in generate_dataset(image_path, labels_path, \n",
        "                                    chip_size=chip_size,\n",
        "                                    channels=channels, \n",
        "                                    grids=grids, \n",
        "                                    allow_empty_chip=allow_empty_chip, \n",
        "                                    rotate=rotate, \n",
        "                                    flip=flip):\n",
        "\n",
        "        X_test =  np.array([item for sublist in X_set for item in sublist])\n",
        "        y_test =  np.array([item for sublist in y_set for item in sublist])\n",
        "\n",
        "        save_dataset(X_test, y_test, test_path, chip_size, channels)\n",
        "\n",
        "def sliding_window(image, step, chip_size, chip_resize):\n",
        "    # slide a chip across the image\n",
        "    step_cols = int(step[0])\n",
        "    step_rows = int(step[1])\n",
        "\n",
        "    cols = image.shape[1]\n",
        "    rows = image.shape[0]\n",
        "\n",
        "    chip_size_cols = chip_size[0]\n",
        "    chip_size_rows = chip_size[1]\n",
        "\n",
        "    chip_resize_cols = chip_resize[0]\n",
        "    chip_resize_rows = chip_resize[1]\n",
        "\n",
        "    for y in range(0, rows, step_rows):\n",
        "        for x in range(0, cols, step_cols):\n",
        "\n",
        "            origin_x = x\n",
        "            origin_y = y\n",
        "\n",
        "            if (origin_y + chip_size_rows) > rows:\n",
        "                origin_y = rows - chip_size_rows\n",
        "\n",
        "            if (origin_x + chip_size_cols) > cols:\n",
        "                origin_x = cols - chip_size_cols\n",
        "\n",
        "            chip = image[origin_y:origin_y + chip_size_rows,\n",
        "                   origin_x: origin_x + chip_size_cols]\n",
        "\n",
        "            original_shape = chip.shape\n",
        "\n",
        "            if chip.shape != (chip_resize_cols, chip_resize_rows):\n",
        "                chip = resize(chip,\n",
        "                              (chip_resize_cols, chip_resize_rows),\n",
        "                              preserve_range=True,\n",
        "                              anti_aliasing=True).astype(np.float16)\n",
        "\n",
        "            yield (origin_x, origin_y, chip, original_shape)\n",
        "\n",
        "\n",
        "def get_window(matrix, x, y, width, height):\n",
        "    return matrix[y:y + height, x:x + width]\n",
        "\n",
        "\n",
        "def set_window(matrix, x, y, new_matrix):\n",
        "    for i_index, i in enumerate(range(y, y + new_matrix.shape[0])):\n",
        "        for j_index, j in enumerate(range(x, x + new_matrix.shape[1])):\n",
        "            matrix[i][j] = new_matrix[i_index][j_index]\n",
        "\n",
        "\n",
        "def transform_labels(labels_array, labels):\n",
        "    lb = preprocessing.LabelBinarizer()\n",
        "    lb.fit(labels)\n",
        "    new_labels_array = []\n",
        "    for ix, l in enumerate(labels_array):\n",
        "        flat_labels = l.reshape((l.shape[0] * l.shape[1],))\n",
        "        transformed_flat_labels = lb.transform(flat_labels)\n",
        "        new_labels_array.append(transformed_flat_labels.reshape(\n",
        "            (l.shape[0], l.shape[1], len(labels))))\n",
        "\n",
        "    new_labels_array = np.array(new_labels_array)\n",
        "    return new_labels_array\n",
        "\n",
        "\n",
        "def get_grids(grids, chip_size):\n",
        "    grids_dict = {\n",
        "        1: [\n",
        "            {\"steps\": (chip_size, chip_size),\n",
        "             \"chip_size\": (chip_size, chip_size)}\n",
        "        ],\n",
        "        2: [\n",
        "            {\"steps\": (int(chip_size * 0.5), int(chip_size * 0.5)),\n",
        "             \"chip_size\": (chip_size, chip_size)},\n",
        "        ],\n",
        "        3: [\n",
        "            {\"steps\": (int(chip_size * 0.9), int(chip_size * 0.9)),\n",
        "             \"chip_size\": (chip_size, chip_size)},\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return grids_dict[grids]\n",
        "\n",
        "\n",
        "def reproject_dataset(g, pixel_spacing=30., epsg_to=3857):\n",
        "    osng = osr.SpatialReference()\n",
        "    osng.ImportFromEPSG(epsg_to)\n",
        "\n",
        "    wkt = g.GetProjection()\n",
        "    wgs84 = osr.SpatialReference()\n",
        "    wgs84.ImportFromWkt(wkt)\n",
        "\n",
        "    tx = osr.CoordinateTransformation(wgs84, osng)\n",
        "    # Up to here, all  the projection have been defined, as well as a\n",
        "    # transformation from the from to the  to :)\n",
        "\n",
        "    # Get the Geotransform vector\n",
        "    geo_t = g.GetGeoTransform()\n",
        "    x_size = g.RasterXSize  # Raster xsize\n",
        "    y_size = g.RasterYSize  # Raster ysize\n",
        "    # Work out the boundaries of the new dataset in the target projection\n",
        "    (ulx, uly, ulz) = tx.TransformPoint(geo_t[0], geo_t[3])\n",
        "    (lrx, lry, lrz) = tx.TransformPoint(geo_t[0] + geo_t[1] * x_size, \\\n",
        "                                        geo_t[3] + geo_t[5] * y_size)\n",
        "\n",
        "    # Now, we create an in-memory raster\n",
        "    mem_drv = gdal.GetDriverByName('MEM')\n",
        "    # The size of the raster is given the new projection and pixel spacing\n",
        "    # Using the values we calculated above. Also, setting it to store one band\n",
        "    # and to use Float32 data type.\n",
        "    dest = mem_drv.Create('', int((lrx - ulx) / pixel_spacing), \\\n",
        "                          int((uly - lry) / pixel_spacing), g.RasterCount,\n",
        "                          g.GetRasterBand(1).DataType)\n",
        "    # Calculate the new geotransform\n",
        "    new_geo = (ulx, pixel_spacing, geo_t[2], \\\n",
        "               uly, geo_t[4], -pixel_spacing)\n",
        "    # Set the geotransform\n",
        "    dest.SetGeoTransform(new_geo)\n",
        "    dest.SetProjection(osng.ExportToWkt())\n",
        "    # Perform the projection/resampling\n",
        "    res = gdal.ReprojectImage(g, dest, \\\n",
        "                              wgs84.ExportToWkt(), osng.ExportToWkt(), \\\n",
        "                              gdal.GRA_NearestNeighbour)\n",
        "    return dest\n",
        "\n",
        "\n",
        "\n",
        "def save_results(original_dataset, reprojected_dataset, image, output_path):\n",
        "    mem_dataset = reprojected_dataset \\\n",
        "        .GetDriver() \\\n",
        "        .Create(output_path, image.shape[1], image.shape[0], 1, gdal.GDT_Int16)\n",
        "\n",
        "    mem_dataset.SetGeoTransform(reprojected_dataset.GetGeoTransform())\n",
        "    mem_dataset.SetProjection(reprojected_dataset.GetProjection())\n",
        "    mem_dataset.GetRasterBand(1) \\\n",
        "        .WriteArray(image.reshape((image.shape[0], image.shape[1])), 0, 0)\n",
        "    mem_dataset.FlushCache()\n",
        "\n",
        "    original_epsg = int(osr \\\n",
        "                        .SpatialReference(wkt=original_dataset.GetProjection()) \\\n",
        "                        .GetAttrValue('AUTHORITY', 1))\n",
        "\n",
        "    output_dataset = reproject_dataset(mem_dataset,\n",
        "                                       SPATIAL_SCALE,\n",
        "                                       original_epsg)\n",
        "\n",
        "    original_dataset.GetDriver().CreateCopy(output_path,\n",
        "                                            output_dataset,\n",
        "                                            options=['COMPRESS=LZW',\n",
        "                                                     'TFW=YES'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOCNbbIp03Df"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKh4wgFDpK9e"
      },
      "source": [
        "## Evaluation Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKBbhFD7yjy2"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred = K.cast(K.greater(y_pred, t), dtype='float32')\n",
        "        inter = K.sum(K.sum(K.squeeze(y_true * y_pred, axis=3), axis=2), axis=1)\n",
        "        union = K.sum(K.sum(K.squeeze(y_true + y_pred, axis=3), axis=2), axis=1) - inter\n",
        "        acc = K.mean((inter + K.epsilon()) / (union + K.epsilon()))\n",
        "        prec.append(acc)\n",
        "    return  K.mean(tf.convert_to_tensor(prec))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b458qR8pRMU"
      },
      "source": [
        "## U-Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9uL77bj08t6"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, Dropout, MaxPooling2D, \\\n",
        "    Conv2DTranspose, concatenate, BatchNormalization, Activation\n",
        "\n",
        "\n",
        "def conv(n_filters, kernel_size, activation='elu', inputs=None):\n",
        "    net = Conv2D(n_filters, kernel_size, activation=None, \\\n",
        "                 kernel_initializer='he_normal', padding='same') (inputs) \n",
        "    net = BatchNormalization()(net)\n",
        "    net = Activation(activation)(net)\n",
        "    return net\n",
        "\n",
        "def transpose(n_filters, kernel_size, activation='elu', inputs=None):\n",
        "    net = Conv2DTranspose(n_filters, kernel_size, activation=None, \n",
        "                          strides=(2, 2), padding='same', \n",
        "                          kernel_initializer='he_normal') (inputs)\n",
        "    net = BatchNormalization()(net)\n",
        "    net = Activation(activation)(net)\n",
        "    return net\n",
        "\n",
        "def model_fn(input_shape, n_filters=64, labels=[]):\n",
        "    print(input_shape, labels)\n",
        "    inputs = keras.Input(input_shape)\n",
        "\n",
        "    c1 = conv(n_filters * 1, (3, 3), inputs=inputs)\n",
        "    c1 = conv(n_filters * 1, (3, 3), inputs=c1)\n",
        "    p1 = MaxPooling2D((2, 2)) (c1)\n",
        "    p1 = Dropout(0.25) (p1)\n",
        "\n",
        "    c2 = conv(n_filters * 2, (3, 3), inputs=p1)\n",
        "    c2 = conv(n_filters * 2, (3, 3), inputs=c2)\n",
        "    p2 = MaxPooling2D((2, 2)) (c2)\n",
        "    p2 = Dropout(0.25) (p2)\n",
        "\n",
        "    c3 = conv(n_filters * 4, (3, 3), inputs=p2)\n",
        "    c3 = conv(n_filters * 4, (3, 3), inputs=c3)\n",
        "    p3 = MaxPooling2D((2, 2)) (c3)\n",
        "    p3 = Dropout(0.5) (p3)\n",
        "\n",
        "    c4 = conv(n_filters * 8, (3, 3), inputs=p3)\n",
        "    c4 = conv(n_filters * 8, (3, 3), inputs=c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "    p4 = Dropout(0.5) (p4)\n",
        "\n",
        "    c5 = conv(n_filters * 16, (3, 3), inputs=p4)\n",
        "    c5 = conv(n_filters * 16, (3, 3), inputs=c5)\n",
        "    c5 = Dropout(0.5) (c5)\n",
        "\n",
        "    u6 = transpose(n_filters * 8, (2, 2), inputs=c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = conv(n_filters * 8, (2, 2), inputs=u6)\n",
        "    c6 = conv(n_filters * 8, (2, 2), inputs=c6)\n",
        "    c6 = Dropout(0.5) (c6)\n",
        "    \n",
        "    u7 = transpose(n_filters * 4, (2, 2), inputs=c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = conv(n_filters * 4, (2, 2), inputs=u7)\n",
        "    c7 = conv(n_filters * 4, (2, 2), inputs=c7)\n",
        "    c7 = Dropout(0.5) (c7)\n",
        "\n",
        "    u8 = transpose(n_filters * 2, (2, 2), inputs=c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = conv(n_filters * 2, (2, 2), inputs=u8)\n",
        "    c8 = conv(n_filters * 2, (2, 2), inputs=c8)\n",
        "    c8 = Dropout(0.25) (c8)\n",
        "    \n",
        "    u9 = transpose(n_filters * 1, (2, 2), inputs=c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = conv(n_filters * 1, (2, 2), inputs=u9)\n",
        "    c9 = conv(n_filters * 1, (2, 2), inputs=c9)\n",
        "    c9 = Dropout(0.25) (c9)\n",
        "    \n",
        "    if len(labels) > 2:\n",
        "        outputs = tf.keras.layers.Conv2D(len(labels), 1, 1, activation='softmax')(c9)\n",
        "        loss_function = 'categorical_crossentropy'\n",
        "        metrics = ['categorical_accuracy']\n",
        "    else:\n",
        "        outputs = conv(1, (1, 1), activation='sigmoid', inputs=c9)\n",
        "        loss_function = 'binary_crossentropy'\n",
        "        metrics = [mean_iou]\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    optimizer = tf.keras.optimizers.Nadam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyfS7rI82Dj4"
      },
      "source": [
        "# Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngmo5JVC2DzF"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from osgeo import gdal\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "class Classifier(object):\n",
        "    def __init__(self, chip_size, channels, model_dir, labels):\n",
        "        self.__chip_size = chip_size\n",
        "        self.__channels = channels\n",
        "        self.__labels = labels\n",
        "        self.__model = model_fn((chip_size, chip_size, channels), labels=labels)\n",
        "        self.__checkpoints = []\n",
        "\n",
        "        if not os.path.exists(model_dir):\n",
        "            os.makedirs(model_dir)\n",
        "\n",
        "        self.load_model(model_dir)\n",
        "        self.load_callbacks(model_dir)\n",
        "\n",
        "    def load_model(self, model_dir):\n",
        "        latest = tf.train.latest_checkpoint(model_dir)\n",
        "\n",
        "        if latest:\n",
        "            print(\"Loading model....\")\n",
        "            self.__model.load_weights(latest)\n",
        "\n",
        "        print(\"Model loaded!\")\n",
        "        self.__model.summary()\n",
        "\n",
        "    def load_callbacks(self, model_dir):\n",
        "        checkpoint_path = \"{dir}/model.ckpt\".format(dir=model_dir)\n",
        "\n",
        "        cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "            filepath=checkpoint_path,\n",
        "            save_weights_only=True,\n",
        "            save_best_only=True)\n",
        "\n",
        "        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=model_dir)\n",
        "\n",
        "        self.__callbacks = [cp_callback, tensorboard_callback]\n",
        "\n",
        "\n",
        "    def train(self, input_train, input_validation, epochs, batch_size):\n",
        "        train_dataset, train_data, train_labels = load_dataset(input_train,\n",
        "                                                            read_only=True)\n",
        "        validation_dataset, validation_data, validation_labels = load_dataset(\n",
        "            input_validation, read_only=True)\n",
        "\n",
        "        train_images = np.asarray(train_data, dtype=np.float16)\n",
        "        train_labels = np.asarray(train_labels, dtype=np.int8)\n",
        "\n",
        "        validation_images = np.asarray(validation_data, dtype=np.float16)\n",
        "        validation_labels = np.asarray(validation_labels, dtype=np.int8)\n",
        "\n",
        "        if len(self.__labels) > 2:\n",
        "            train_labels = transform_labels(train_labels, self.__labels)\n",
        "            validation_labels = transform_labels(validation_labels,\n",
        "                                                 self.__labels)\n",
        "\n",
        "        print(train_images.shape)\n",
        "        print(train_labels.shape)\n",
        "\n",
        "        print(\"\\nTrain: {train_size}\\n Validation: {validation_size}\".format(\n",
        "            train_size=train_images.shape[0], \n",
        "            validation_size=validation_images.shape[0]))\n",
        "\n",
        "        self.__model.fit(x=train_images,\n",
        "                         y=train_labels,\n",
        "                         validation_data=(validation_images, validation_labels),\n",
        "                         epochs=epochs,\n",
        "                         batch_size=batch_size,\n",
        "                         verbose=1,\n",
        "                         callbacks=self.__callbacks,\n",
        "                         shuffle=True)\n",
        "        \n",
        "        train_dataset.close()\n",
        "        validation_dataset.close()\n",
        "\n",
        "    def evaluate(self, input_test, batch_size):\n",
        "        test_file, test_data, test_labels = load_dataset(input_test,\n",
        "                                                         read_only=True)\n",
        "\n",
        "        test_data = np.asarray(test_data, dtype=np.float16)\n",
        "        test_labels = np.asarray(test_labels, dtype=np.int8)\n",
        "\n",
        "        test_results = self.__model.evaluate(test_data,\n",
        "                                             test_labels,\n",
        "                                             batch_size=batch_size)\n",
        "\n",
        "        print('test loss, test acc:', test_results)\n",
        "\n",
        "    def predict(self, input_path, output_path, grids, batch_size):\n",
        "        original_dataset, input_dataset, image = load_file(input_path,\n",
        "                                                           norm=True)\n",
        "\n",
        "        image = image[:, :, : self.__channels]\n",
        "\n",
        "        predicted_image = np.zeros((image.shape[0], image.shape[1]),\n",
        "                                   dtype=np.int8)\n",
        "\n",
        "        grids = get_grids(grids, self.__chip_size)\n",
        "\n",
        "        for step in grids:\n",
        "            batch = []\n",
        "            windows = sliding_window(image, step[\"steps\"], step[\"chip_size\"],\n",
        "                                     (self.__chip_size, self.__chip_size))\n",
        "\n",
        "            for (x, y, chip, original_dimensions) in tqdm(iterable=windows,\n",
        "                                                          miniters=10,\n",
        "                                                          unit=\" windows\"):\n",
        "\n",
        "                normalized_chip = normalize(chip)\n",
        "\n",
        "                batch.append({\n",
        "                    \"chip\": normalized_chip,\n",
        "                    \"x\": x,\n",
        "                    \"y\": y,\n",
        "                    \"dimensions\": original_dimensions\n",
        "                })\n",
        "\n",
        "                if len(batch) >= batch_size:\n",
        "                    chips = []\n",
        "                    positions = []\n",
        "                    dimensions = []\n",
        "\n",
        "                    for b in batch:\n",
        "                        chips.append(b.get(\"chip\"))\n",
        "                        positions.append((b.get(\"x\"), b.get(\"y\")))\n",
        "                        dimensions.append(b.get(\"dimensions\"))\n",
        "\n",
        "                    chips = np.array(chips, dtype=np.float16)\n",
        "\n",
        "                    pred = self.__model.predict(chips, batch_size=batch_size)\n",
        "\n",
        "                    for chip, position, dimension, predict in zip(chips,\n",
        "                                                                  positions,\n",
        "                                                                  dimensions,\n",
        "                                                                  pred):\n",
        "\n",
        "                        if len(self.__labels) > 2:\n",
        "                            predict = np.array(tf.math.argmax(predict, axis=2))\n",
        "                        else:\n",
        "                            predict[predict > 0.5] = 1\n",
        "                            predict[predict <= 0.5] = 0\n",
        "\n",
        "                        predict = resize(predict, (dimension[0], dimension[1]),\n",
        "                                         preserve_range=True,\n",
        "                                         anti_aliasing=True).astype(np.int8)\n",
        "\n",
        "                        predict = predict.reshape(\n",
        "                            (predict.shape[0], predict.shape[1]))\n",
        "\n",
        "                        predicted = get_window(predicted_image,\n",
        "                                               position[0],\n",
        "                                               position[1],\n",
        "                                               predict.shape[1],\n",
        "                                               predict.shape[0])\n",
        "\n",
        "                        if predict.shape != predicted.shape:\n",
        "                            raise Exception(\"predict.shape != predicted.shape\")\n",
        "\n",
        "                        if len(self.__labels) > 2:\n",
        "                            set_window(predicted_image, position[0],\n",
        "                                       position[1], predict)\n",
        "                        else:\n",
        "                            set_window(predicted_image, position[0],\n",
        "                                       position[1], np.add(predict, predicted))\n",
        "\n",
        "                    batch = []\n",
        "\n",
        "            if len(self.__labels) == 2:\n",
        "                predicted_image[predicted_image >= 1] = 1\n",
        "                \n",
        "            print(\"Saving results...\")\n",
        "            save_results(original_dataset, input_dataset, predicted_image,\n",
        "                      output_path)\n",
        "            print(\"Finished!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVZGp46G9d2b"
      },
      "source": [
        "# Use Our Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkQtBl5DaWOt"
      },
      "source": [
        "What do you think about mapping center pivot irrigation systems anywhere in the world?\n",
        "\n",
        "First, you will need to build an image that will be used as an input to our model. \n",
        "\n",
        "To build this image, you can use this [script](https://code.earthengine.google.com/026e25d88be2e3cc808c9a2d6d269a01) that must be run on Google Earth Engine platform.\n",
        "\n",
        "Following the instructions in the script, it will export an image into the MAPBIOMAS-PRIVATE directory on your Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDcbK0cn2cfc"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join, sep, exists\n",
        "\n",
        "classifier = Classifier(chip_size=PREDICT_CHIP_SIZE,\n",
        "                        channels=CHANNELS,\n",
        "                        model_dir=MODEL_DIR,\n",
        "                        labels=LABELS)\n",
        "\n",
        "if not  os.path.exists(PREDICT_INPUT_DIR):\n",
        "    print(\"Please wait until Google Earth Engine finishes processing your task.\")\n",
        "\n",
        "files = [f for f in listdir(PREDICT_INPUT_DIR) if\n",
        "         isfile(join(PREDICT_INPUT_DIR, f))]\n",
        "\n",
        "if len(files) == 0:\n",
        "    print(\"No file found.\")\n",
        "\n",
        "for f in files:\n",
        "    print(\"File:\", f)\n",
        "    input_file = \"{directory}/{filepath}\".format(directory=PREDICT_INPUT_DIR, filepath=f)\n",
        "\n",
        "    output_file = \"{directory}/{filepath}\".format(directory=PREDICT_OUPUT_DIR, filepath=f)\n",
        "\n",
        "    if not os.path.exists(PREDICT_OUPUT_DIR):\n",
        "            os.makedirs(PREDICT_OUPUT_DIR)\n",
        "\n",
        "    if exists(output_file):\n",
        "        print(\"File {} exists. Skipping...\".format(output_file))\n",
        "        continue\n",
        "\n",
        "    print(\"Predict: \", input_file, \"  >>  \", output_file)\n",
        "\n",
        "    classifier.predict(input_path=input_file, output_path=output_file,\n",
        "                       grids=PREDICT_GRIDS,\n",
        "                       batch_size=PREDICT_BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G62gUubn1eme"
      },
      "source": [
        "# Train Your Own Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DydlXKwXKt1n"
      },
      "source": [
        "## Build Train and Validation datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzuSbSOAJtlq"
      },
      "source": [
        "import glob\n",
        "\n",
        "images = [f for f in glob.glob(TRAIN_VALIDATION_DIR + \"/*mosaic.tif\", recursive=True)]\n",
        "\n",
        "if len(images) == 0:\n",
        "    print(\"No samples found.\")\n",
        "\n",
        "for image_path in images:\n",
        "    labels_path = image_path.replace(\"mosaic\", \"labels\")\n",
        "    print(image_path)\n",
        "    print(labels_path)\n",
        "    generate_train_validation_dataset(\n",
        "        image_path=image_path,\n",
        "        labels_path=labels_path,\n",
        "        train_path=TRAIN_PATH,\n",
        "        validation_path=VALIDATION_PATH,\n",
        "        chip_size=CHIP_SIZE,\n",
        "        channels=CHANNELS,\n",
        "        grids=GRIDS,\n",
        "        rotate=ROTATE\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97VWhc-1RK5s"
      },
      "source": [
        "MODEL_DIR = \"/content/drive/My Drive/MAPBIOMAS-PRIVATE/logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIhJy8c7Kwgn"
      },
      "source": [
        "## Plot Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAGlCBcZK5Ay"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "\n",
        "def plot_figures(figures, nrows = 1, ncols=1):\n",
        "    \"\"\"Plot a dictionary of figures.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    figures : <title, figure> dictionary\n",
        "    ncols : number of columns of subplots wanted in the display\n",
        "    nrows : number of rows of subplots wanted in the figure\n",
        "    \"\"\"\n",
        "\n",
        "    fig, axeslist = plt.subplots(ncols=ncols, nrows=nrows, figsize=(19, 10))\n",
        "    for ind,title in zip(range(len(figures)), figures):\n",
        "        image = figures[title]\n",
        "        if image.shape[2] >= 3:\n",
        "            image = image[:, : , :3]\n",
        "            axeslist.ravel()[ind].imshow(image, vmin=0.1, vmax=0.4)\n",
        "        else:\n",
        "            image = image.reshape((image.shape[0], image.shape[1]))\n",
        "            axeslist.ravel()[ind].imshow(image)\n",
        "        axeslist.ravel()[ind].set_title(title)\n",
        "        axeslist.ravel()[ind].set_axis_off()\n",
        "    plt.tight_layout() # optional\n",
        "\n",
        "figures = {}\n",
        "\n",
        "dataset, x, y = load_dataset(TRAIN_PATH, read_only=True)\n",
        "\n",
        "ids = []\n",
        "\n",
        "samples = 4\n",
        "\n",
        "for i in range(0, samples):\n",
        "    id = random.randint(0,x.shape[0])\n",
        "    figures['img_x'+ str(i)] = x[id]\n",
        "    figures['img_y'+ str(i)] = y[id]\n",
        "\n",
        "plot_figures(figures, 2, samples)\n",
        "dataset.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQXkIsGIk8f5"
      },
      "source": [
        "## Run Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZZgZqYB1fl9"
      },
      "source": [
        "classifier = Classifier(chip_size=CHIP_SIZE,\n",
        "                        channels=CHANNELS,\n",
        "                        model_dir=MODEL_DIR,\n",
        "                        labels=LABELS)\n",
        "\n",
        "classifier.train(\n",
        "    input_train=TRAIN_PATH,\n",
        "    input_validation=VALIDATION_PATH,\n",
        "    epochs=TRAIN_EPOCHS,\n",
        "    batch_size=TRAIN_BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZKPCpCwOeBs"
      },
      "source": [
        "## Evaluate your trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6SPQLaRS_0L"
      },
      "source": [
        "### Build Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veChduIjTC7I"
      },
      "source": [
        "import glob\n",
        "\n",
        "images = [f for f in glob.glob(TEST_DIR + \"/*mosaic.tif\", recursive=True)]\n",
        "\n",
        "if len(images) == 0:\n",
        "    print(\"No test found.\")\n",
        "\n",
        "for image_path in images:\n",
        "    labels_path = image_path.replace(\"mosaic\", \"labels\")\n",
        "    print(image_path)\n",
        "    print(labels_path)\n",
        "    generate_test_dataset(\n",
        "        image_path=image_path,\n",
        "        labels_path=labels_path,\n",
        "        test_path=TEST_PATH,\n",
        "        chip_size=CHIP_SIZE,\n",
        "        channels=CHANNELS,\n",
        "        grids=1,\n",
        "        allow_empty_chip=True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQrxITsHlyZ_"
      },
      "source": [
        "### Run Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoig24NpOgpw"
      },
      "source": [
        "classifier = Classifier(chip_size=CHIP_SIZE,\n",
        "                        channels=CHANNELS,\n",
        "                        model_dir=MODEL_DIR,\n",
        "                        labels=LABELS)\n",
        "\n",
        "classifier.evaluate(\n",
        "    input_test=TEST_PATH,\n",
        "    batch_size=TRAIN_BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}